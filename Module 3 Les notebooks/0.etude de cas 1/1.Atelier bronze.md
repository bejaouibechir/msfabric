# ATELIER 1 : BRONZE - IMPORT DES DONN√âES


*Lakehouse** : Lakehouse_bronze  
**Objectif** : Charger les donn√©es brutes et identifier les probl√®mes de qualit√©

---

## üéØ Objectif de l'atelier

Charger les donn√©es brutes dans la couche Bronze et identifier les probl√®mes de qualit√©. Cette premi√®re √©tape consiste √† ing√©rer les donn√©es ¬´ telles quelles ¬ª sans transformation, en appliquant le principe du data lake : **conserver la source de v√©rit√©**.

---

## üìä Contexte m√©tier

Vous √™tes data engineer pour un parc de **6 sites de production/consommation √©lectrique**. Les donn√©es arrivent de capteurs IoT toutes les 15 minutes sous forme de fichiers CSV. Votre mission : les centraliser dans un lakehouse pour analyse.

**Probl√®me connu** : Ces donn√©es brutes contiennent des erreurs (capteurs d√©faillants, transmissions r√©seau, formats incoh√©rents). Il est imp√©ratif de les conserver intactes en Bronze avant nettoyage en Silver.

---

## üìù Cellule 1 : Configuration et v√©rification Spark

### üîç Avant d'ex√©cuter

**Objectif** : V√©rifier que l'environnement Spark est op√©rationnel et que le notebook est bien connect√© au bon lakehouse.

**Variables cl√©s** :

- `spark.version` : Version du moteur Spark (ex: 3.5.5)
- `Lakehouse_bronze` : Nom du lakehouse o√π les donn√©es Bronze seront stock√©es

### üíª Code

```python
# V√©rifier que Spark est disponible
print(f"‚úÖ Spark version: {spark.version}")
print(f"‚úÖ Lakehouse par d√©faut: Lakehouse_bronze")
```

### üì§ R√©sultat

```
‚úÖ Spark version: 3.5.5.5.4.20251218.3
‚úÖ Lakehouse par d√©faut: Lakehouse_bronze
```

### üí° Interpr√©tation

‚úÖ **Environnement valid√©** : Spark fonctionne correctement et le notebook est attach√© √† Lakehouse_bronze.

**Point cl√©** : Cette v√©rification pr√©liminaire √©vite les erreurs d'ex√©cution dues √† une mauvaise configuration. En production, on ajouterait des tests sur les droits d'acc√®s au lakehouse.

---

## üìù Cellule 2 : Import consumption_raw.csv

### üîç Avant d'ex√©cuter

**Objectif** : Charger le fichier CSV de consommation brute et cr√©er une table Delta dans le sch√©ma bronze. Cette table contiendra **TOUTES** les donn√©es, y compris les erreurs.

**Variables et concepts cl√©s** :

- `spark.read.csv()` : Lit un fichier CSV en parall√®le (distribu√© sur plusieurs n≈ìuds Spark)
- `option("inferSchema", "true")` : Spark d√©tecte automatiquement les types de colonnes (string, int, double, etc.)
- `.format("delta")` : Format Delta Lake (ACID, time travel, optimisations)
- `bronze.consumption_raw` : Notation sch√©ma.table dans le lakehouse

### üíª Code

```python
# Charger le CSV avec PySpark
df_consumption = spark.read.format("csv") \
    .option("header", "true") \
    .option("inferSchema", "true") \
    .load("Files/data_bronze_notebooks/consumption_raw.csv")

# Cr√©er la table dans le sch√©ma bronze
df_consumption.write.mode("overwrite").format("delta").saveAsTable("bronze.consumption_raw")

print(f"‚úÖ Table bronze.consumption_raw cr√©√©e : {df_consumption.count()} lignes")
```

### üì§ R√©sultat

```
‚úÖ Table bronze.consumption_raw cr√©√©e : 18144 lignes
```

### üí° Interpr√©tation

üìä **Volume de donn√©es** : 18,144 lignes correspondent √† ~30 jours de donn√©es pour 6 sites avec mesures toutes les 15 minutes :

- Calcul : 6 sites √ó 4 mesures/heure √ó 24h √ó 30j ‚âà 17,280 lignes th√©oriques
- Les 864 lignes suppl√©mentaires sont des **doublons** (retransmissions r√©seau)

‚úÖ **Succ√®s de l'op√©ration** : La table Delta est cr√©√©e et accessible via SQL. Le format Delta garantit :

- **Atomicit√©** : Soit tout est √©crit, soit rien
- **Tra√ßabilit√©** : Historique des versions (time travel)
- **Optimisations** : Compression, indexation automatique

‚ö†Ô∏è **Attention** : Ce nombre inclut les doublons et erreurs. C'est **NORMAL** en Bronze ‚Äì on nettoiera en Silver.

---

## üìù Cellule 3 : Premi√®re vue des donn√©es

### üîç Avant d'ex√©cuter

**Objectif** : Visualiser rapidement les donn√©es brutes pour rep√©rer les anomalies √©videntes.

### üíª Code

```sql
%%sql
SELECT * FROM bronze.consumption_raw LIMIT 20
```

### üì§ R√©sultat

Extrait des 20 premi√®res lignes montrant :

- ‚úÖ Donn√©es normales (OK)
- ‚ùå Valeurs NULL (ERROR)
- ‚ùå Codes erreur n√©gatifs (-888, ERROR)
- ‚ö†Ô∏è Formats de dates multiples (2025-01-11T13:30:00 vs 17/01/2025 18:15:00)

### üí° Interpr√©tation

**Observations visuelles** :

- Dates en **3 formats diff√©rents** : ISO 8601, fran√ßais, am√©ricain
- Valeurs `NULL` dans `consumption_mw` = capteur d√©faillant
- Codes `-888`, `-999`, `-777` = modes d√©grad√©s des capteurs
- Status `ERROR` corr√©l√© avec valeurs anormales

**Le√ßon Bronze** : On **GARDE TOUT** tel quel. La normalisation viendra en Silver.

---

## üìù Cellule 4 : D√©tection des probl√®mes de qualit√©

### üîç Avant d'ex√©cuter

**Objectif** : Quantifier les probl√®mes de qualit√© pour pr√©parer le nettoyage Silver. Cette analyse diagnostique est cruciale pour anticiper les transformations n√©cessaires.

**M√©triques calcul√©es** :

- `total_rows` : Nombre total de lignes
- `unique_rows` : Lignes uniques (timestamp, site_id)
- `duplicates` : Doublons (retransmissions r√©seau)
- `null_values` : Valeurs NULL (capteur d√©faillant)
- `error_codes` : Codes erreur n√©gatifs (-999, -888, -777)
- `outliers` : Valeurs aberrantes (> 10 MW au-del√† de la capacit√©)

### üíª Code

```sql
%%sql
-- Compter les NULL, codes erreur, doublons
SELECT 
    COUNT(*) as total_rows,
    COUNT(DISTINCT timestamp, site_id) as unique_rows,
    COUNT(*) - COUNT(DISTINCT timestamp, site_id) as duplicates,
    SUM(CASE WHEN consumption_mw IS NULL THEN 1 ELSE 0 END) as null_values,
    SUM(CASE WHEN consumption_mw < 0 THEN 1 ELSE 0 END) as error_codes,
    SUM(CASE WHEN consumption_mw > 10 THEN 1 ELSE 0 END) as outliers
FROM bronze.consumption_raw
```

### üì§ R√©sultat

| total_rows | unique_rows | duplicates | null_values | error_codes | outliers |
| ---------- | ----------- | ---------- | ----------- | ----------- | -------- |
| **18144**  | **17280**   | **864**    | **554**     | **319**     | **27**   |

### üí° Interpr√©tation d√©taill√©e

üìä **Analyse quantitative** :

- **864 doublons (4.8%)** : Retransmissions r√©seau typiques des capteurs IoT. √Ä supprimer en Silver via `DISTINCT`.

- **554 NULL (3.1%)** : Capteurs d√©faillants temporairement. Options :
  
  - Interpolation lin√©aire si < 5% manquant par site
  - Suppression si criticit√© faible

- **319 codes erreur (1.8%)** : Codes `-999`/`-888`/`-777` envoy√©s par les capteurs en mode d√©grad√©. √Ä filtrer syst√©matiquement.

- **27 outliers (0.1%)** : Pics > 10 MW alors que capacit√© max = 5 MW. Probablement :
  
  - Erreurs de calibration capteur
  - Bugs firmware
  - √Ä investiguer manuellement si > 0.5%

‚úÖ **Qualit√© globale** : **9.8%** de donn√©es probl√©matiques (~1,764 lignes).

C'est **dans la norme** pour des donn√©es IoT brutes. Le taux de perte apr√®s nettoyage devrait √™tre **< 10%**.

üéØ **Actions Silver prioris√©es** :

- **Priorit√© 1** : Doublons et codes erreur (faciles, r√®gles simples)
- **Priorit√© 2** : NULL et outliers (n√©cessitent analyse m√©tier)

---

## üìù Cellule 5 : Import des autres fichiers

### üîç Avant d'ex√©cuter

**Objectif** : Charger les 4 tables compl√©mentaires n√©cessaires √† l'analyse compl√®te.

**Tables** :

- `market_prices` : Prix spot √©lectricit√© (‚Ç¨/MWh)
- `weather_data` : M√©t√©o (temp√©rature, vent, humidit√©)
- `sites_reference` : R√©f√©rentiel des 6 sites (capacit√©, type, r√©gion)
- `maintenance_events` : √âv√©nements de maintenance planifi√©e

### üíª Code

```python
# Market prices
spark.read.csv("Files/data_bronze_notebooks/market_prices.csv", header=True, inferSchema=True) \
    .write.mode("overwrite").format("delta").saveAsTable("bronze.market_prices")

# Weather
spark.read.csv("Files/data_bronze_notebooks/weather_data.csv", header=True, inferSchema=True) \
    .write.mode("overwrite").format("delta").saveAsTable("bronze.weather_data")

# Sites reference
spark.read.csv("Files/data_bronze_notebooks/sites_reference.csv", header=True, inferSchema=True) \
    .write.mode("overwrite").format("delta").saveAsTable("bronze.sites_reference")

# Maintenance events
spark.read.csv("Files/data_bronze_notebooks/maintenance_events.csv", header=True, inferSchema=True) \
    .write.mode("overwrite").format("delta").saveAsTable("bronze.maintenance_events")

print("‚úÖ Toutes les tables Bronze cr√©√©es")
```

### üì§ R√©sultat

```
‚úÖ Toutes les tables Bronze cr√©√©es
```

### üí° Interpr√©tation

‚úÖ **Import batch r√©ussi** : Les 4 tables compl√©mentaires sont cr√©√©es en une seule ex√©cution.

**Point technique** : L'option `inferSchema=True` d√©tecte automatiquement :

- Timestamps ‚Üí type `timestamp`
- Prix, capacit√©s ‚Üí type `double`
- IDs, r√©gions ‚Üí type `string`

---

## üìù Cellule 6 : V√©rification de toutes les tables

### üîç Avant d'ex√©cuter

**Objectif** : Valider que toutes les tables Bronze sont cr√©√©es avec le bon volume de donn√©es. C'est un **contr√¥le qualit√©** avant de passer √† Silver.

**Tables attendues** :

- `consumption_raw` : Mesures de consommation
- `market_prices` : Prix spot march√©
- `weather_data` : Donn√©es m√©t√©o
- `sites_reference` : R√©f√©rentiel sites
- `maintenance_events` : √âv√©nements maintenance

### üíª Code

```sql
%%sql
SELECT 'consumption' as table_name, COUNT(*) as rows FROM bronze.consumption_raw
UNION ALL
SELECT 'prices', COUNT(*) FROM bronze.market_prices
UNION ALL
SELECT 'weather', COUNT(*) FROM bronze.weather_data
UNION ALL
SELECT 'sites', COUNT(*) FROM bronze.sites_reference
UNION ALL
SELECT 'maintenance', COUNT(*) FROM bronze.maintenance_events
```

### üì§ R√©sultat

| table_name  | rows  |
| ----------- | ----- |
| consumption | 18144 |
| prices      | 2880  |
| weather     | 720   |
| sites       | 6     |
| maintenance | 8     |

### üí° Interpr√©tation

‚úÖ **Import complet valid√©** : Toutes les tables attendues sont pr√©sentes avec des volumes coh√©rents.

üìä **Analyse des volumes** :

- **2,880 prix spot** : 30 jours √ó 24h √ó 4 mesures/heure = 2,880 (donn√©es propres, **pas de doublons**)

- **720 m√©t√©o** : 30 jours √ó 24h = 720 mesures horaires (temp√©rature, vent, humidit√©)

- **6 sites** : R√©f√©rentiel statique avec r√©partition :
  
  - 2 sites Industrie (5 MW, 3.5 MW)
  - 2 sites Commercial (2 MW, 1.5 MW)
  - 2 sites R√©sidentiel (0.8 MW, 0.6 MW)

- **8 maintenances** : √âv√©nements de maintenance planifi√©e (impact sur production)

**Coh√©rence valid√©e** : Le ratio consommation/m√©t√©o/prix = 25:1:4 est conforme au mod√®le de donn√©es.

---

## üìù Cellule 7 : R√©sum√©

### ‚úÖ Bronze import termin√©

**Donn√©es charg√©es** :

- ~18,144 lignes de consommation (dont ~900 doublons, ~540 NULL, ~360 codes erreur)
- 2,880 lignes de prix spot
- 720 lignes m√©t√©o
- 6 sites
- 8 √©v√©nements maintenance

**Probl√®mes d√©tect√©s** :

- ‚ùå 5% doublons
- ‚ùå 3% valeurs NULL
- ‚ùå 2% codes erreur (-999, -888, -777)
- ‚ùå Formats de dates multiples
- ‚ùå Valeurs aberrantes (> 10 MW)

‚û°Ô∏è **Prochaine √©tape** : Nettoyage dans Silver (Notebook 2)

---

## üéØ Synth√®se de l'Atelier Bronze

### ‚úÖ Objectifs atteints

- **Import r√©ussi** : 5 tables Delta cr√©√©es dans le sch√©ma bronze (21,758 lignes au total)
- **Diagnostic qualit√©** : 9.8% de donn√©es probl√©matiques identifi√©es et quantifi√©es
- **Principe Bronze valid√©** : Donn√©es brutes conserv√©es intactes (source de v√©rit√©)

### üìã Points cl√©s √† retenir

- **Format Delta Lake** : ACID, time travel, optimisations de stockage automatiques
- **Spark SQL efficace** : Pour import et exploration, SQL est optimal (syntaxe d√©clarative, rapide)
- **Diagnostic pr√©coce** : Identifier les probl√®mes d√®s Bronze = gain de temps en Silver

### üîÑ Prochaine √©tape : Silver (Notebook 2)

**Objectif Silver** : Nettoyer, standardiser et enrichir les donn√©es pour les rendre exploitables.

**Transformations pr√©vues** :

- Suppression doublons (`DISTINCT`)
- Filtrage NULL et codes erreur
- Normalisation formats dates
- Jointures (prix + m√©t√©o + r√©f√©rentiel)

‚ö†Ô∏è **Limite SQL d√©couverte** : Calculs avanc√©s impossibles ‚Üí PySpark n√©cessaire (Notebook 3)

### üéì Le√ßon m√©tier

**Bronze = parking des donn√©es brutes**. On garde **TOUT** pour tra√ßabilit√© et rejouabilit√©. Le nettoyage aggressif vient apr√®s, jamais avant.

---

**‚úÖ ATELIER 1 TERMIN√â**  
Passez √† l'Atelier 2 : Silver - Nettoyage
