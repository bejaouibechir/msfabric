{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 : Silver 1 - Nettoyage (Spark SQL)\n",
    "\n",
    "**Dur√©e** : 15 minutes  \n",
    "**Lakehouse** : Lakehouse_silver  \n",
    "**Objectif** : Nettoyer les donn√©es et identifier les limites de SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 1 : Chargement depuis Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM bronze.consumption_raw LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 2 : Suppression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMP VIEW consumption_dedup AS\n",
    "SELECT DISTINCT * FROM bronze.consumption_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 3 : Filtrage des codes erreur et NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMP VIEW consumption_clean AS\n",
    "SELECT * FROM consumption_dedup\n",
    "WHERE consumption_mw IS NOT NULL \n",
    "  AND consumption_mw >= 0\n",
    "  AND consumption_mw < 10  -- Retirer valeurs aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 4 : V√©rification du nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    COUNT(*) as clean_rows,\n",
    "    (SELECT COUNT(*) FROM bronze.consumption_raw) as original_rows,\n",
    "    (SELECT COUNT(*) FROM bronze.consumption_raw) - COUNT(*) as removed_rows\n",
    "FROM consumption_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 5 : Normalisation des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMP VIEW consumption_dates_fixed AS\n",
    "SELECT \n",
    "    site_id,\n",
    "    consumption_mw,\n",
    "    voltage_v,\n",
    "    frequency_hz,\n",
    "    status,\n",
    "    COALESCE(\n",
    "        TRY_CAST(timestamp AS TIMESTAMP),\n",
    "        TO_TIMESTAMP(timestamp, 'dd/MM/yyyy HH:mm:ss'),\n",
    "        TO_TIMESTAMP(timestamp, 'yyyy-MM-dd HH:mm:ss')\n",
    "    ) as timestamp_clean\n",
    "FROM consumption_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 6 : Agr√©gation horaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMP VIEW consumption_hourly AS\n",
    "SELECT \n",
    "    DATE_TRUNC('hour', timestamp_clean) as hour,\n",
    "    site_id,\n",
    "    AVG(consumption_mw) as avg_consumption_mw,\n",
    "    MAX(consumption_mw) as max_consumption_mw,\n",
    "    MIN(consumption_mw) as min_consumption_mw,\n",
    "    COUNT(*) as measurements\n",
    "FROM consumption_dates_fixed\n",
    "WHERE timestamp_clean IS NOT NULL\n",
    "GROUP BY DATE_TRUNC('hour', timestamp_clean), site_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 7 : Jointure avec prix spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMP VIEW consumption_with_prices AS\n",
    "SELECT \n",
    "    c.*,\n",
    "    p.price_eur_mwh,\n",
    "    p.market\n",
    "FROM consumption_hourly c\n",
    "LEFT JOIN bronze.market_prices p\n",
    "  ON DATE_TRUNC('hour', c.hour) = DATE_TRUNC('hour', CAST(p.timestamp AS TIMESTAMP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 8 : ‚ö†Ô∏è LIMITE SQL - Logique m√©tier complexe\n",
    "\n",
    "### Probl√®me rencontr√©\n",
    "\n",
    "**T√¢che** : Appliquer des r√®gles m√©tier complexes (calcul de baseline intelligente, z-score, interpolation)\n",
    "\n",
    "**Limites de SQL** :\n",
    "- ‚ùå Pas d'UDF (User Defined Functions) pour logique custom\n",
    "- ‚ùå CASE WHEN devient illisible avec >10 r√®gles\n",
    "- ‚ùå Impossible d'impl√©menter des algorithmes it√©ratifs\n",
    "- ‚ùå Pas d'interpolation, pas de z-score simple\n",
    "\n",
    "**üí° C'EST ICI QU'ON PASSE √Ä PYSPARK**\n",
    "\n",
    "Avec PySpark :\n",
    "- ‚úÖ UDF custom en Python (5 lignes)\n",
    "- ‚úÖ Logique m√©tier lisible et maintenable\n",
    "- ‚úÖ Fonctions math√©matiques avanc√©es\n",
    "- ‚úÖ 10√ó plus rapide pour calculs complexes\n",
    "\n",
    "‚Üí **Notebook 3 : PySpark d√©bloque tout √ßa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 9 : Sauvegarde partielle dans Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder ce qu'on a nettoy√©\n",
    "df = spark.sql(\"SELECT * FROM consumption_with_prices\")\n",
    "df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"silver.consumption_clean\")\n",
    "\n",
    "print(f\"‚úÖ Table silver.consumption_clean cr√©√©e : {df.count()} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellule 10 : R√©sum√©\n",
    "\n",
    "### ‚úÖ Nettoyage SQL termin√©\n",
    "\n",
    "**Ce qu'on a fait avec SQL** :\n",
    "- ‚úÖ Suppression doublons (~900 lignes)\n",
    "- ‚úÖ Filtrage NULL et codes erreur (~900 lignes)\n",
    "- ‚úÖ Normalisation formats de dates\n",
    "- ‚úÖ Agr√©gation horaire\n",
    "- ‚úÖ Jointure avec prix spot\n",
    "\n",
    "**Ce qu'on NE PEUT PAS faire avec SQL** :\n",
    "- ‚ùå Calcul baseline intelligente (exclure weekends + maintenance)\n",
    "- ‚ùå D√©tection anomalies avec z-score\n",
    "- ‚ùå Feature engineering pour ML\n",
    "- ‚ùå UDF personnalis√©es\n",
    "\n",
    "**R√©sultat** :\n",
    "- ~16,300 lignes propres sauvegard√©es dans `silver.consumption_clean`\n",
    "\n",
    "‚û°Ô∏è **Prochaine √©tape** : PySpark pour calculs avanc√©s (Notebook 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
