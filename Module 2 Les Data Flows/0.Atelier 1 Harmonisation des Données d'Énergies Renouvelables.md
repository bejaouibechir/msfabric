# Atelier Dataflow Gen2 - Harmonisation des DonnÃ©es d'Ã‰nergies Renouvelables

## ğŸ“Œ Introduction

### Contexte

Vous Ãªtes data engineer chez **GreenEnergy France**, un opÃ©rateur multi-Ã©nergies qui gÃ¨re :

- 4 parcs solaires (Paris, Lyon, Marseille, Bordeaux)
- 5 parcs Ã©oliens (Normandie, Bretagne, Picardie, Pays de la Loire, Centre)
- 3 centrales hydrauliques (RhÃ´ne, Alpes, PyrÃ©nÃ©es)

**Objectif de l'atelier** : CrÃ©er un pipeline automatisÃ© pour harmoniser les donnÃ©es hÃ©tÃ©rogÃ¨nes et alimenter un dashboard de monitoring unifiÃ©.

---

## ğŸ” Ã‰tat des lieux

### Sources de donnÃ©es actuelles

| Fichier                              | Lignes | ProblÃ¨mes                                                                                        |
| ------------------------------------ | ------ | ------------------------------------------------------------------------------------------------ |
| **solaire_2025.csv**                 | 1,460  | âŒ Valeurs NaN<br>âŒ Codes erreur -888<br>âŒ Nomenclature incohÃ©rente                               |
| **eolien_2025.csv**                  | 1,975  | âŒ 150 doublons exacts<br>âŒ Ã‰tats "Duplicate"<br>âŒ UnitÃ©s en MWh (vs kWh)                         |
| **hydro_2025.csv**                   | 2,190  | âŒ 2 formats de dates (DD/MM/YYYY et YYYY-MM-DD)<br>âŒ Noms variables (HYD_RHONE vs HYD_RHONE-var) |
| **calendrier_meteo_maintenance.csv** | 365    | âœ… DonnÃ©es propres                                                                                |

### Exemple de donnÃ©es problÃ©matiques

**Solaire** :

```csv
timestamp,parc_id,type,production_kwh,irradiation_kwh_m2,temperature_c,status
2025-01-01,SOL_PARIS,solaire,4250.5,4.8,15.2,OK
2025-01-01,SOL_LYON,solaire,NaN,3.2,18.5,FAULT        â† NaN
2025-01-02,SOL_MARSEILLE,solaire,-888,5.1,22.3,INVERTER â† Code erreur
```

**Ã‰olien** :

```csv
date,parc_code,prod_mwh,vent_mps,etat
2025-01-15,EOL_BRETAGNE,8.45,12.3,Running
2025-01-15,EOL_BRETAGNE,8.45,12.3,Running  â† DOUBLON
2025-01-15,EOL_BRETAGNE,8.45,12.3,Duplicate
```

**Hydro** :

```csv
ReadingDate,PlantID,Production_kWh,Debit_m3_s,Niveau_m,Alert
01/01/2025,HYD_RHONE,18500.2,32.5,75.2,None           â† Format DD/MM/YYYY
2025-01-01,HYD_RHONE-var,18350.8,31.8,74.9,LowFlow   â† Format YYYY-MM-DD
```

---

## âš ï¸ ProblÃ©matique

### 3 problÃ¨mes critiques

**1. Silos de donnÃ©es incompatibles**

- SchÃ©mas diffÃ©rents (parc_id vs parc_code vs PlantID)
- Formats de dates multiples
- UnitÃ©s hÃ©tÃ©rogÃ¨nes (kWh vs MWh)
- **Impact** : 2-3 heures/jour de prÃ©paration manuelle dans Excel

**2. QualitÃ© de donnÃ©es mÃ©diocre**

- Doublons â†’ Surestimation de 1,268 MWh = **190,200 â‚¬ d'erreur potentielle**
- Valeurs manquantes â†’ Calculs de moyennes faussÃ©s
- Codes erreur â†’ Production nÃ©gative comptabilisÃ©e

**3. Absence d'orchestration**

- Processus manuel : donnÃ©es disponibles Ã  11h30 (vs arrivÃ©e Ã  6h00)
- Pas de planification automatique
- Pas de contexte mÃ©tier (mÃ©tÃ©o, maintenance)

---

## ğŸ’¡ Comment Dataflow Gen2 rÃ©sout ces problÃ¨mes

### Pourquoi Dataflow Gen2 ?

| Besoin                       | Solution Dataflow Gen2                                   |
| ---------------------------- | -------------------------------------------------------- |
| **Unifier 4 sources**        | Ingestion multi-sources native + Power Query visuel      |
| **Nettoyer automatiquement** | Transformations M (suppression doublons, filtres, types) |
| **Enrichir avec contexte**   | Jointures (mÃ©tÃ©o + calendrier)                           |
| **Automatiser**              | Pipeline planifiÃ© (tous les jours Ã  6h15)                |
| **Stocker optimisÃ©**         | Lakehouse Delta avec mode Append (historique)            |

**ğŸ†• NouveautÃ©s 2025 disponibles** :

- **Copilot intÃ©grÃ©** : CrÃ©er des transformations en langage naturel
- **Modern Evaluator** : 20-30% plus rapide que l'ancien moteur
- **Partitioned Compute** : Traitement parallÃ¨le des fichiers (ADLS Gen2, Lakehouse)
- **RÃ©duction de coÃ»t** : 25% de rÃ©duction sur les 10 premiÃ¨res minutes (pricing 2-tier)
- **OneLake Catalog** : DÃ©couverte simplifiÃ©e des sources Fabric

### Architecture cible

```
Sources CSV â†’ Dataflow Gen2 â†’ Lakehouse (Delta) â†’ Power BI Dashboard
                â†“
        [Nettoyage + Transformations + Enrichissement]
                â†“
        Pipeline (planification quotidienne)
```

---

## ğŸ› ï¸ Mise en Å“uvre pas Ã  pas

### PrÃ©requis

- âœ… Workspace Fabric
- âœ… Lakehouse `LH_Energies_Renouvelables` crÃ©Ã©
- âœ… Fichiers CSV uploadÃ©s dans `/Files/data_renewable/`

---

### Ã‰TAPE 1 : CrÃ©er le Dataflow Gen2

**1.1 Initialisation**

1. Workspace â†’ **+ New** â†’ **Dataflow Gen2**
2. Nom : `DF_Harmonisation_Production_Renouvelable`

**1.2 Ingestion des 4 sources**

1. **Get data** â†’ **OneLake data hub**
2. Naviguer vers : `Lakehouse â†’ Files â†’ data_renewable`
3. SÃ©lectionner les 4 fichiers CSV :
   - solaire_2025.csv
   - eolien_2025.csv
   - hydro_2025.csv
   - calendrier_meteo_maintenance.csv
4. **Create** â†’ Power Query Editor s'ouvre

---

### Ã‰TAPE 2 : Nettoyage des donnÃ©es

#### 2.1 RequÃªte `solaire_2025`

**Actions Ã  effectuer** :

1. **Transform** â†’ **Detect Data Type** (types automatiques)

2. **Home** â†’ **Remove Rows** â†’ **Remove Errors** (sur production_kwh)

3. **Home** â†’ **Filter Rows** â†’ production_kwh â‰  -888

4. **Home** â†’ **Remove Duplicates** (sÃ©lectionner timestamp + parc_id)

5. **Transform** â†’ **Rename** : timestamp â†’ date

6. **Transform** â†’ **Data Type** : date â†’ Date (sans heure)

7. **Add Column** â†’ **Custom Column** :
   
   ```
   Nom : rendement_pctFormule : if [irradiation_kwh_m2] > 0 then ([production_kwh] / [irradiation_kwh_m2]) * 100 else null
   ```

**RÃ©sultat** : 1,460 â†’ 1,370 lignes (-6% de donnÃ©es invalides)

---

#### 2.2 RequÃªte `eolien_2025`

**Actions** :

1. **Home** â†’ **Remove Duplicates** (toutes les colonnes)

2. **Home** â†’ **Filter Rows** â†’ etat â‰  "Duplicate"

3. **Add Column** â†’ **Custom Column** :
   
   ```
   Nom : production_kwhFormule : [prod_mwh] * 1000
   ```

4. **Transform** â†’ **Rename** : parc_code â†’ parc_id

5. **Add Column** â†’ **Custom Column** :
   
   ```
   Nom : typeFormule : "eolien"
   ```

**RÃ©sultat** : 1,975 â†’ 1,770 lignes (-10% de doublons)

---

#### 2.3 RequÃªte `hydro_2025`

**Actions** :

1. SÃ©lectionner colonne PlantID â†’ **Transform** â†’ **Replace Values** :
   
   - Chercher : `-var`
   - Remplacer : (vide)

2. **Transform** â†’ **Data Type** â†’ Date (pour ReadingDate)

3. **Home** â†’ **Remove Duplicates** (ReadingDate + PlantID)

4. **Transform** â†’ **Rename** :
   
   - ReadingDate â†’ date
   - PlantID â†’ parc_id
   - Production_kWh â†’ production_kwh

5. **Add Column** â†’ **Custom Column** :
   
   ```
   Nom : typeFormule : "hydro"
   ```

**RÃ©sultat** : 2,190 â†’ 1,095 lignes (-50% normal : fusion des variantes)

---

#### 2.4 RequÃªte `calendrier_meteo_maintenance`

**Actions** :

1. **Transform** â†’ **Detect Data Type** (automatique)

Aucun nettoyage nÃ©cessaire (donnÃ©es propres).

---

### Ã‰TAPE 3 : Fusion et enrichissement

#### 3.1 Fusionner les 3 sources Ã©nergÃ©tiques

1. **Home** â†’ **Append Queries** â†’ **Append Queries as New**
2. SÃ©lectionner :
   - solaire_2025
   - eolien_2025
   - hydro_2025
3. Nom : `production_all_types`

**RÃ©sultat** : Table unifiÃ©e avec schÃ©ma harmonisÃ© (date, parc_id, type, production_kwh)

---

#### 3.2 Enrichir avec mÃ©tÃ©o/calendrier

1. SÃ©lectionner `production_all_types`
2. **Home** â†’ **Merge Queries** â†’ **Merge Queries as New**
3. Configuration :
   - Table gauche : production_all_types
   - Table droite : calendrier_meteo_maintenance
   - Colonnes : date = date
   - Join : Left Outer
4. Nom : `production_enrichie`
5. Cliquer sur l'icÃ´ne â‡„ â†’ SÃ©lectionner :
   - weekend
   - maintenance
   - pluie_mm
   - vent_mps (renommer en vent_mps_meteo)
   - jour
   - mois

---

#### 3.3 Colonnes calculÃ©es finales

**Add Column** â†’ **Custom Column** (rÃ©pÃ©ter 3 fois) :

**1. Production ajustÃ©e** :

```
Nom : production_kwh_ajustee
Formule : if [maintenance] = 1 then null else [production_kwh]
```

**2. CapacitÃ© nominale** :

```
Nom : capacite_nominale_kwh
Formule : if [type] = "solaire" then 5000 
          else if [type] = "eolien" then 10000 
          else if [type] = "hydro" then 20000 
          else null
```

**3. Facteur de charge** :

```
Nom : facteur_charge_pct
Formule : if [capacite_nominale_kwh] > 0 
          then ([production_kwh] / [capacite_nominale_kwh]) * 100 
          else null
```

---

### Ã‰TAPE 4 : Configuration de la destination

1. SÃ©lectionner la requÃªte **production_enrichie**

2. **Add data destination** (en bas Ã  droite) â†’ **Lakehouse**

3. Configuration :
   
   - Workspace : (votre workspace)
   - Lakehouse : LH_Energies_Renouvelables
   - Table : `production_energies_renouvelables`
   - Update method : **Append**

4. **Publish** (en haut Ã  droite)

---

### Ã‰TAPE 5 : Test manuel

1. Aller dans le Workspace
2. Trouver `DF_Harmonisation_Production_Renouvelable`
3. **â‹¯** â†’ **Refresh now**
4. Attendre 2-3 minutes
5. VÃ©rifier : Statut = "Succeeded"

---

### Ã‰TAPE 6 : Validation des donnÃ©es

**Dans le Lakehouse** :

1. Ouvrir `LH_Energies_Renouvelables`
2. **Tables** â†’ `production_energies_renouvelables`
3. **SQL analytics endpoint** â†’ **New SQL query**

**RequÃªte de validation** :

```sql
-- VÃ©rifier le nombre de lignes par type
SELECT 
    type,
    COUNT(*) as nb_lignes,
    MIN(date) as date_min,
    MAX(date) as date_max
FROM production_energies_renouvelables
GROUP BY type
ORDER BY type;

-- RÃ©sultat attendu :
-- eolien  | 1770 | 2025-01-01 | 2025-12-31
-- hydro   | 1095 | 2025-01-01 | 2025-12-31
-- solaire | 1370 | 2025-01-01 | 2025-12-31
```

**VÃ©rifier l'absence de doublons** :

```sql
SELECT date, parc_id, COUNT(*) as nb
FROM production_energies_renouvelables
GROUP BY date, parc_id
HAVING COUNT(*) > 1;

-- RÃ©sultat attendu : 0 lignes
```

---

### Ã‰TAPE 7 : Orchestration avec Pipeline

**7.1 CrÃ©er le Pipeline**

1. Workspace â†’ **+ New** â†’ **Data pipeline**
2. Nom : `Pipeline_Daily_Energy_Refresh`

**7.2 Ajouter les activitÃ©s**

1. **Activities** â†’ **Dataflow** â†’ Glisser sur le canvas
2. **Settings** â†’ Dataflow : `DF_Harmonisation_Production_Renouvelable`
3. **Activities** â†’ **Office365 Outlook** â†’ **Send email** (notification succÃ¨s)
4. Connecter Dataflow â†’ Email avec flÃ¨che "On Success"

**7.3 Planification**

1. **Home** â†’ **Schedule**
2. Configuration :
   - Repeat : Daily
   - Time : 06:15
   - Time zone : (UTC+01:00) Paris
   - Start date : (aujourd'hui)

**7.4 Gestion d'erreurs**

1. SÃ©lectionner activitÃ© Dataflow

2. **Settings** â†’ **Advanced** :
   
   - Retry : 3
   - Retry interval : 60 seconds
   - Timeout : 1 hour

3. **Save** â†’ **Run** (test)

---

### Ã‰TAPE 8 (Optionnelle) : Activer les optimisations 2025

**ğŸš€ Pour amÃ©liorer les performances (recommandÃ©)** :

1. Ouvrir le Dataflow `DF_Harmonisation_Production_Renouvelable`
2. **Home** â†’ **Options**
3. Onglet **Scale** :
   - â˜‘ï¸ **Query evaluation** (Modern Evaluator) â†’ Gain de 20-30% de vitesse
   - â˜‘ï¸ **Partitioned compute** â†’ Traitement parallÃ¨le (si applicable)
4. **OK** â†’ **Publish**

**RÃ©sultat attendu** :

```
Sans optimisations : 2-3 minutes de refresh
Avec Modern Evaluator : 1.5-2 minutes de refresh
â†’ Gain de 30% de temps ET de coÃ»ts CU
```

---

## ğŸ¯ Conclusion et interprÃ©tation

### Ce qui a Ã©tÃ© accompli

**Transformation des donnÃ©es** :

```
AVANT                           APRÃˆS
5,625 lignes brutes        â†’    4,235 lignes propres
4 schÃ©mas diffÃ©rents       â†’    1 schÃ©ma unifiÃ©
DonnÃ©es isolÃ©es            â†’    Enrichies (mÃ©tÃ©o + calendrier)
Process manuel (3h/jour)   â†’    AutomatisÃ© (5 min/jour â†’ 1.5 min avec optimisations 2025)
```

**QualitÃ© obtenue** :

- âœ… **0 doublon** (150 Ã©liminÃ©s de l'Ã©olien)
- âœ… **0 code erreur** (90 lignes -888 supprimÃ©es)
- âœ… **0 valeur manquante** (NaN filtrÃ©s)
- âœ… **Dates unifiÃ©es** (2 formats â†’ 1 format standard)
- âœ… **UnitÃ©s harmonisÃ©es** (MWh â†’ kWh)

### Indicateurs mÃ©tier crÃ©Ã©s

**KPIs disponibles immÃ©diatement** :

1. **Production totale** : ~36,405 MWh/an
   
   - Hydro : 47% (production de base)
   - Ã‰olien : 39% (variable)
   - Solaire : 14% (saisonnier)

2. **Facteur de charge** :
   
   - Hydro : 86% (excellent)
   - Ã‰olien : 39% (conforme aux standards)
   - Solaire : 28% (normal pour France)

3. **DisponibilitÃ©** :
   
   - Hydro : 99% (ultra-fiable)
   - Ã‰olien : 96%
   - Solaire : 93% (Ã  investiguer)

### Valeur mÃ©tier

**Gains quantifiables** :

- â±ï¸ **Temps Ã©conomisÃ©** : 2h/jour Ã— 250 jours = 500h/an = **30,000 â‚¬/an**
- ğŸ’° **Erreurs Ã©vitÃ©es** : Doublons Ã©liminÃ©s = **190,200 â‚¬** d'erreurs de dÃ©cision
- ğŸš€ **Time-to-insight** : 5h30 â†’ 5 minutes (refresh automatique)
- ğŸ’¸ **RÃ©duction coÃ»ts CU (2025)** : Avec Modern Evaluator = **30% de CU Ã©conomisÃ©s**

**CapacitÃ©s dÃ©bloquÃ©es** :

- âœ… Dashboard temps rÃ©el unifiÃ©
- âœ… Alertes automatiques sur anomalies
- âœ… Analyses contextuelles (production vs mÃ©tÃ©o)
- âœ… Historique complet conservÃ© (Delta Lake)
- âœ… Base solide pour ML prÃ©dictif (prochaine Ã©tape)
- ğŸ†• **Copilot IA** : Transformations en langage naturel disponibles
