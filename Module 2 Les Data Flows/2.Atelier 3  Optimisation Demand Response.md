# Atelier Dataflow Gen2 - Optimisation Demand Response (Effacement de Consommation)

## ğŸ“Œ Introduction

### Contexte

Vous Ãªtes data engineer chez **FlexEnergy**, un agrÃ©gateur qui pilote l'effacement de consommation Ã©lectrique pour Ã©quilibrer le rÃ©seau et profiter des pics de prix.

**Objectif de l'atelier** : CrÃ©er un pipeline quasi-temps rÃ©el pour dÃ©tecter les opportunitÃ©s d'effacement et optimiser l'utilisation des batteries.

---

## ğŸ” Ã‰tat des lieux

### Sources de donnÃ©es actuelles

| Fichier                          | Lignes | GranularitÃ©   | ProblÃ¨mes                                                                                         |
| -------------------------------- | ------ | ------------- | ------------------------------------------------------------------------------------------------- |
| **consommation_iot_15min.csv**   | ~4,100 | 15 min        | âŒ Doublons (2% transmission rÃ©seau)<br>âŒ Codes erreur -99<br>âŒ Valeurs NaN (capteurs dÃ©faillants) |
| **etat_batteries_15min.csv**     | ~2,020 | 15 min        | âŒ Trous de donnÃ©es (maintenance)<br>âŒ Interpolation nÃ©cessaire                                    |
| **prix_spot_marche_15min.csv**   | ~670   | 15 min        | âœ… DonnÃ©es propres                                                                                 |
| **previsions_meteo_horaire.csv** | ~170   | 1 heure       | âœ… DonnÃ©es propres (mais granularitÃ© diffÃ©rente)                                                   |
| **referentiel_sites.csv**        | 6      | RÃ©fÃ©rence     | âœ… DonnÃ©es propres                                                                                 |
| **evenements_maintenance.csv**   | ~5     | Ã‰vÃ©nements    | âœ… DonnÃ©es propres                                                                                 |
| **seuils_alerte.csv**            | 5      | Configuration | âœ… DonnÃ©es propres                                                                                 |

### Exemple de donnÃ©es problÃ©matiques

**Consommation IoT** :

```csv
timestamp,site_id,consommation_mw,tension_v,frequence_hz,status_capteur
2025-01-20 08:00:00,SITE_IND_001,3.450,232.1,50.02,OK
2025-01-20 08:00:00,SITE_IND_001,3.450,232.1,50.02,OK  â† DOUBLON
2025-01-20 08:15:00,SITE_IND_001,NaN,229.5,49.98,ERREUR  â† Capteur dÃ©faillant
2025-01-20 08:30:00,SITE_IND_002,-99,0,0,ERREUR  â† Code erreur
```

**Batteries (trous de donnÃ©es)** :

```csv
timestamp,batterie_id,site_id,soc_pct,puissance_mw
2025-01-20 10:00:00,BAT_001,SITE_IND_001,45.2,0.5
2025-01-20 10:15:00,BAT_001,SITE_IND_001,NaN,NaN  â† Maintenance
2025-01-20 10:30:00,BAT_001,SITE_IND_001,NaN,NaN  â† Maintenance
2025-01-20 10:45:00,BAT_001,SITE_IND_001,46.8,0.3  â† Retour
```

---

## âš ï¸ ProblÃ©matique

### 3 dÃ©fis critiques

**1. DonnÃ©es temps rÃ©el sales et incomplÃ¨tes**

- Doublons â†’ Surestimation de la consommation
- Codes erreur â†’ Calculs faussÃ©s
- Trous de donnÃ©es batteries â†’ Impossible d'optimiser la dÃ©charge
- **Impact** : DÃ©cisions d'effacement basÃ©es sur donnÃ©es incorrectes

**2. Impossible de dÃ©tecter les opportunitÃ©s d'effacement**

- Prix spot et consommation dans des fichiers sÃ©parÃ©s
- Pas de vue unifiÃ©e prix Ã— consommation Ã— flexibilitÃ©
- Pas d'alertes automatiques quand prix > 200 â‚¬/MWh
- **CoÃ»t d'opportunitÃ©** : Pertes de revenus d'effacement

**3. Pas d'agrÃ©gation temporelle pour le pilotage**

- DonnÃ©es brutes 15 min â†’ Impossible de voir les tendances horaires
- Pas de baseline (consommation attendue sans effacement)
- Pas de calcul de flexibilitÃ© disponible
- **Impact** : Pilotage Ã  l'aveugle

---

## ğŸ’¡ Comment Dataflow Gen2 rÃ©sout ces problÃ¨mes

### Solution proposÃ©e

| Besoin                          | Solution Dataflow Gen2                                             |
| ------------------------------- | ------------------------------------------------------------------ |
| **Nettoyer donnÃ©es temps rÃ©el** | Suppression doublons + filtrage codes erreur + interpolation trous |
| **DÃ©tecter opportunitÃ©s**       | Jointure consommation Ã— prix Ã— sites flexibles                     |
| **Calculer baseline**           | Group By horaire + calcul moyenne glissante                        |
| **Alertes automatiques**        | Colonnes calculÃ©es (si prix > seuil â†’ alerte)                      |
| **GÃ©rer granularitÃ© mixte**     | AgrÃ©gation 15min â†’ 1h pour jointure mÃ©tÃ©o                          |

### Architecture cible

```
7 sources CSV â†’ Dataflow Gen2 â†’ Lakehouse â†’ Notebook ML (optimisation)
                     â†“
       [Nettoyage + AgrÃ©gation + Enrichissement]
                     â†“
       Pipeline (refresh toutes les 15 min en production)
```

---

## ğŸ› ï¸ Mise en Å“uvre pas Ã  pas

### PrÃ©requis

- âœ… Workspace Fabric
- âœ… Lakehouse `LH_Demand_Response` crÃ©Ã©
- âœ… Fichiers CSV uploadÃ©s dans `/Files/data_demand_response/`

---

### Ã‰TAPE 1 : CrÃ©er le Dataflow Gen2

**1.1 Initialisation**

1. Workspace â†’ **+ New** â†’ **Dataflow Gen2**
2. Nom : `DF_Optimisation_Demand_Response`

**1.2 Ingestion des 7 sources**

1. **Get data** â†’ **OneLake data hub**
2. Naviguer : `Lakehouse â†’ Files â†’ data_demand_response`
3. SÃ©lectionner les 7 fichiers CSV
4. **Create**

---

### Ã‰TAPE 2 : Nettoyage des donnÃ©es IoT

#### 2.1 RequÃªte `consommation_iot_15min`

**Actions** :

1. **Home** â†’ **Remove Duplicates** (toutes colonnes)
2. **Home** â†’ **Filter Rows** :
   - consommation_mw â‰  -99
   - status_capteur = "OK"
3. **Home** â†’ **Remove Rows** â†’ **Remove Errors** (consommation_mw)
4. **Transform** â†’ **Data Type** : timestamp â†’ DateTime

**RÃ©sultat** : ~4,100 â†’ ~3,950 lignes (-4% invalides)

---

#### 2.2 Interpolation des valeurs manquantes (optionnel avancÃ©)

**Si trous courts (< 1 heure)**, interpoler :

**Add Column** â†’ **Custom Column** :

```m
Nom : consommation_mw_interpole
Formule : 
let
    valeur_actuelle = [consommation_mw],
    valeur_precedente = try #"Cleaned Rows"{[Index]-1}[consommation_mw] otherwise null,
    valeur_suivante = try #"Cleaned Rows"{[Index]+1}[consommation_mw] otherwise null
in
    if valeur_actuelle = null and valeur_precedente <> null and valeur_suivante <> null
    then (valeur_precedente + valeur_suivante) / 2
    else valeur_actuelle
```

**âš ï¸ Note** : L'interpolation avancÃ©e est complexe en Power Query. Pour production, utiliser un Notebook Python en amont.

---

#### 2.3 RequÃªte `etat_batteries_15min`

**Actions** :

1. **Transform** â†’ **Data Type** : timestamp â†’ DateTime
2. **Home** â†’ **Remove Rows** â†’ **Remove Errors** (soc_pct, puissance_mw)

**Pour les trous de maintenance** :

- Option 1 : Les laisser (NULL) et les ignorer dans les calculs
- Option 2 : Interpolation linÃ©aire (mÃªme formule que ci-dessus)

**RÃ©sultat** : ~2,020 â†’ ~1,960 lignes

---

### Ã‰TAPE 3 : AgrÃ©gation temporelle

#### 3.1 AgrÃ©gation horaire de la consommation

1. Dupliquer `consommation_iot_15min` â†’ Nom : `consommation_horaire`

2. **Add Column** â†’ **Custom Column** :
   
   ```
   Nom : heureFormule : DateTime.Date([timestamp]) & #time(Time.Hour([timestamp]), 0, 0)
   ```
   
   â†’ Ceci arrondit Ã  l'heure la plus proche

**Alternative plus simple** :

```
Nom : heure
Formule : Date.AddHours(DateTime.Date([timestamp]), Time.Hour([timestamp]))
```

3. **Transform** â†’ **Group By** :
   - Grouper par : heure, site_id
   - AgrÃ©gations :
     - consommation_moyenne_mw = Average(consommation_mw)
     - consommation_max_mw = Max(consommation_mw)
     - consommation_min_mw = Min(consommation_mw)
     - nb_mesures = Count(Rows)

---

#### 3.2 AgrÃ©gation horaire des batteries

1. Dupliquer `etat_batteries_15min` â†’ Nom : `batteries_horaire`
2. Ajouter colonne `heure` (mÃªme mÃ©thode)
3. **Group By** :
   - Grouper par : heure, batterie_id, site_id
   - AgrÃ©gations :
     - soc_moyen_pct = Average(soc_pct)
     - puissance_moyenne_mw = Average(puissance_mw)

---

### Ã‰TAPE 4 : Calcul de la baseline (consommation attendue)

#### 4.1 Baseline par site (moyenne des 3 derniers jours)

Sur `consommation_horaire` :

**Add Column** â†’ **Custom Column** :

```m
Nom : baseline_mw
Formule : [consommation_moyenne_mw]  // Simplification : baseline = moyenne observÃ©e
```

**Pour une vraie baseline** (ML), il faudrait :

- Historique de plusieurs semaines
- ModÃ¨le prÃ©dictif tenant compte de jour/heure/mÃ©tÃ©o
- â†’ Ã€ faire dans un Notebook Python ultÃ©rieurement

**Simplification pÃ©dagogique** : On prend la moyenne observÃ©e comme baseline

---

### Ã‰TAPE 5 : Enrichissement avec prix et mÃ©tÃ©o

#### 5.1 AgrÃ©gation horaire des prix spot

1. Dupliquer `prix_spot_marche_15min` â†’ Nom : `prix_horaire`
2. Ajouter colonne `heure`
3. **Group By** :
   - Grouper par : heure
   - AgrÃ©gations :
     - prix_spot_moyen_eur_mwh = Average(prix_spot_eur_mwh)
     - prix_spot_max_eur_mwh = Max(prix_spot_eur_mwh)

---

#### 5.2 Jointure consommation + prix

1. SÃ©lectionner `consommation_horaire`
2. **Merge Queries as New** :
   - Droite : prix_horaire
   - Colonnes : heure = heure
   - Join : Left Outer
3. Nom : `consommation_prix`
4. Expand : prix_spot_moyen_eur_mwh, prix_spot_max_eur_mwh

---

#### 5.3 Jointure avec mÃ©tÃ©o

1. Sur `consommation_prix`
2. **Merge Queries** :
   - Droite : previsions_meteo_horaire
   - Colonnes : heure = timestamp
   - Join : Left Outer
3. Expand : temperature_c, humidite_pct, vitesse_vent_ms

---

#### 5.4 Jointure avec rÃ©fÃ©rentiel sites

1. Sur `consommation_prix` (dÃ©jÃ  enrichie mÃ©tÃ©o)
2. **Merge Queries** :
   - Droite : referentiel_sites
   - Colonnes : site_id = site_id
   - Join : Left Outer
3. Expand :
   - type_site
   - flexible
   - baseline_mw (renommer en baseline_ref_mw)
   - prix_effacement_eur_mwh

---

### Ã‰TAPE 6 : DÃ©tection des opportunitÃ©s d'effacement

#### 6.1 Charger les seuils d'alerte

RequÃªte `seuils_alerte` â†’ Garder telle quelle (table de configuration)

Pour simplifier, on va utiliser des seuils en dur dans les formules.

---

#### 6.2 Calculer les signaux d'alerte

Sur `consommation_prix` (enrichie) :

**Add Column** â†’ **Custom Column** :

```m
Nom : signal_prix
Formule : 
if [prix_spot_moyen_eur_mwh] >= 300 then "ğŸ”´ PRIX_TRES_ELEVE"
else if [prix_spot_moyen_eur_mwh] >= 200 then "ğŸŸ  PRIX_ELEVE"
else "ğŸŸ¢ PRIX_NORMAL"
```

**Add Column** â†’ **Custom Column** :

```m
Nom : action_recommandee
Formule : 
if [flexible] = true and [signal_prix] = "ğŸ”´ PRIX_TRES_ELEVE" 
then "Effacement max + DÃ©charge batteries"
else if [flexible] = true and [signal_prix] = "ğŸŸ  PRIX_ELEVE"
then "Effacement partiel"
else "Aucune action"
```

**Add Column** â†’ **Custom Column** :

```m
Nom : potentiel_gain_eur
Formule : 
if [action_recommandee] <> "Aucune action"
then ([consommation_moyenne_mw] * 0.3) * [prix_effacement_eur_mwh]  // 30% effacement
else 0
```

---

#### 6.3 DÃ©tecter les anomalies de consommation

**Add Column** â†’ **Custom Column** :

```m
Nom : ratio_vs_baseline
Formule : [consommation_moyenne_mw] / [baseline_ref_mw]
```

**Add Column** â†’ **Custom Column** :

```m
Nom : anomalie_conso
Formule : 
if [ratio_vs_baseline] > 1.5 then "âš ï¸ Consommation anormalement haute"
else if [ratio_vs_baseline] < 0.5 then "âš ï¸ Consommation anormalement basse"
else "Normal"
```

---

### Ã‰TAPE 7 : Enrichissement batteries

#### 7.1 Jointure batteries + consommation

1. SÃ©lectionner `batteries_horaire`
2. **Merge Queries as New** :
   - Droite : consommation_prix (enrichie)
   - Colonnes : heure = heure ET site_id = site_id
   - Join : Left Outer
3. Nom : `batteries_enrichies`
4. Expand : prix_spot_moyen_eur_mwh, signal_prix

---

#### 7.2 Calculer les recommandations batteries

**Add Column** â†’ **Custom Column** :

```m
Nom : action_batterie
Formule : 
if [soc_moyen_pct] < 20 then "âš¡ Charger (SOC bas)"
else if [soc_moyen_pct] > 90 then "ğŸ’¡ DÃ©charger (SOC haut)"
else if [signal_prix] = "ğŸ”´ PRIX_TRES_ELEVE" and [soc_moyen_pct] > 40
then "ğŸ’° DÃ©charger (prix Ã©levÃ©)"
else if [signal_prix] = "ğŸŸ¢ PRIX_NORMAL" and [soc_moyen_pct] < 80
then "ğŸ”‹ Charger (prix bas)"
else "Aucune action"
```

**Add Column** â†’ **Custom Column** :

```m
Nom : gain_decharge_eur
Formule : 
if Text.Contains([action_batterie], "DÃ©charger")
then [puissance_moyenne_mw] * [prix_spot_moyen_eur_mwh]
else 0
```

---

### Ã‰TAPE 8 : Traiter les maintenances

#### 8.1 Joindre avec Ã©vÃ©nements de maintenance

1. Sur `consommation_prix`
2. **Merge Queries** :
   - Droite : evenements_maintenance
   - Colonnes : site_id = site_id
   - Join : Left Outer
3. Expand : debut_maintenance, fin_maintenance, statut

#### 8.2 Flaguer les pÃ©riodes de maintenance

**Add Column** â†’ **Custom Column** :

```m
Nom : en_maintenance
Formule : 
[heure] >= [debut_maintenance] and [heure] <= [fin_maintenance]
```

**Filtrer les calculs** :

- Si `en_maintenance = true` â†’ Exclure des calculs d'effacement

---

### Ã‰TAPE 9 : Configuration des destinations

#### 9.1 Table principale : consommation_optimisee

1. SÃ©lectionner `consommation_prix` (entiÃ¨rement enrichie)
2. **Add data destination** â†’ **Lakehouse**
3. Configuration :
   - Table : `consommation_optimisee_horaire`
   - Update method : **Append**

#### 9.2 Table batteries

1. SÃ©lectionner `batteries_enrichies`
2. **Add data destination** â†’ **Lakehouse**
3. Configuration :
   - Table : `batteries_etat_optimise`
   - Update method : **Append**

#### 9.3 Table alertes uniquement

1. Dupliquer `consommation_prix` â†’ Nom : `alertes_actives`

2. **Filter Rows** :
   
   - signal_prix â‰  "ğŸŸ¢ PRIX_NORMAL"
   - OU anomalie_conso â‰  "Normal"

3. **Add data destination** â†’ Lakehouse

4. Configuration :
   
   - Table : `alertes_demand_response`
   - Update method : **Replace** (seules les alertes actuelles)

5. **Publish**

---

### Ã‰TAPE 10 : Test et validation

**10.1 Premier refresh**

1. Workspace â†’ Dataflow â†’ **Refresh now**
2. DurÃ©e attendue : 2-3 minutes

**10.2 Validation dans Lakehouse**

```sql
-- 1. Compter les opportunitÃ©s d'effacement
SELECT 
    signal_prix,
    COUNT(*) as nb_periodes,
    SUM(potentiel_gain_eur) as gain_total_eur
FROM consommation_optimisee_horaire
WHERE action_recommandee <> 'Aucune action'
GROUP BY signal_prix;

-- RÃ©sultat attendu :
-- ğŸŸ  PRIX_ELEVE      : ~20 pÃ©riodes, ~15,000 â‚¬ gain potentiel
-- ğŸ”´ PRIX_TRES_ELEVE : ~5 pÃ©riodes, ~8,000 â‚¬ gain potentiel

-- 2. Analyser l'Ã©tat des batteries
SELECT 
    action_batterie,
    COUNT(*) as nb_periodes,
    ROUND(AVG(soc_moyen_pct), 1) as soc_moyen,
    ROUND(SUM(gain_decharge_eur), 0) as gain_total_eur
FROM batteries_etat_optimise
GROUP BY action_batterie
ORDER BY gain_total_eur DESC;

-- RÃ©sultat attendu :
-- ğŸ’° DÃ©charger (prix Ã©levÃ©) : ~30 pÃ©riodes, SOC 65%, ~12,000 â‚¬ gain

-- 3. Alertes actives actuellement
SELECT 
    heure,
    site_id,
    signal_prix,
    anomalie_conso,
    action_recommandee
FROM alertes_demand_response
ORDER BY heure DESC
LIMIT 10;
```

---

### Ã‰TAPE 11 : Pipeline refresh frÃ©quent

**11.1 CrÃ©er le Pipeline**

1. Workspace â†’ **+ New** â†’ **Data pipeline**
2. Nom : `Pipeline_Demand_Response_15min`

**11.2 ActivitÃ©s**

1. **Dataflow** : `DF_Optimisation_Demand_Response`
2. **Notebook** (optionnel) : Optimisation ML (calcul flexibilitÃ© optimale)
3. **Send email** (On Failure) : "âŒ Ã‰chec refresh Demand Response"

**11.3 Planification**

- Repeat : **Every 15 minutes** (production)
- Pour l'atelier : **Hourly** ou **Manual**

**âš ï¸ Note** : En production rÃ©elle, on utiliserait :

- **Event-driven trigger** (dÃ¨s rÃ©ception nouvelles donnÃ©es IoT)
- Ou **Streaming** avec Eventstream + KQL Database

**11.4 Gestion d'erreurs**

- Retry : 2 (pas trop pour ne pas retarder les dÃ©cisions)
- Retry interval : 30 seconds
- Timeout : 10 minutes

---

## ğŸ¯ Conclusion et interprÃ©tation

### Transformation effectuÃ©e

```
AVANT                                APRÃˆS
7 fichiers isolÃ©s               â†’    3 tables optimisÃ©es
DonnÃ©es brutes 15 min           â†’    AgrÃ©gations horaires
Pas de calcul d'opportunitÃ©     â†’    DÃ©tection automatique prix > 200 â‚¬/MWh
Pas de baseline                 â†’    Baseline + ratio d'anomalie
Process manuel                  â†’    Pipeline automatisÃ© 15 min
```

### KPIs Demand Response crÃ©Ã©s

**1. OpportunitÃ©s d'effacement dÃ©tectÃ©es**

- PÃ©riodes prix Ã©levÃ© (>200 â‚¬/MWh) : ~25 pÃ©riodes/semaine
- Gain potentiel total : ~23,000 â‚¬/semaine
- Sites flexibles activables : 4/6 (67%)

**2. Optimisation batteries**

- PÃ©riodes dÃ©charge optimale : ~30 pÃ©riodes/semaine
- Gain par arbitrage prix : ~12,000 â‚¬/semaine
- SOC moyen : 65% (optimal pour flexibilitÃ©)

**3. Anomalies dÃ©tectÃ©es**

- Consommations anormales : 15 alertes/semaine
- Ã‰conomies potentielles (correction) : ~5,000 â‚¬/semaine

**4. DisponibilitÃ© donnÃ©es**

- Taux de complÃ©tude : 96% (aprÃ¨s nettoyage vs 91% brut)
- Temps de latence : < 20 minutes (donnÃ©es â†’ dÃ©cision)

### Valeur mÃ©tier

**Gains quantifiables** :

- ğŸ’° **Revenus effacement** : 23,000 â‚¬/semaine Ã— 52 = **1,196,000 â‚¬/an**
- ğŸ”‹ **Revenus batteries** : 12,000 â‚¬/semaine Ã— 52 = **624,000 â‚¬/an**
- ğŸ“‰ **Ã‰conomies anomalies** : 5,000 â‚¬/semaine Ã— 52 = **260,000 â‚¬/an**
- **TOTAL : 2,080,000 â‚¬/an**

**CapacitÃ©s opÃ©rationnelles** :

- âœ… DÃ©tection automatique opportunitÃ©s (vs manuelle)
- âœ… Alertes temps rÃ©el si prix > seuil
- âœ… Optimisation batteries basÃ©e sur prix spot
- âœ… TraÃ§abilitÃ© complÃ¨te (maintenances exclues)
- âœ… Base propre pour ML prÃ©dictif (prochaine Ã©tape)

**Prochaines Ã©tapes** :

1. **Notebook Python** : ModÃ¨le ML pour prÃ©dire baseline (consommation attendue)
2. **Optimisation avancÃ©e** : Algorithme d'optimisation pour maximiser gain (effacement + batteries)
3. **Streaming temps rÃ©el** : Passer de batch 15 min Ã  streaming continu (Eventstream)
4. **API de pilotage** : Envoyer les commandes d'effacement automatiquement aux sites
