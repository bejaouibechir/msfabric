# Atelier : Supervision d'une centrale Biogaz avec Azure Event Hub & Microsoft Fabric

Vous allez construire deux pipelines d'ingestion temps r√©el pour superviser une centrale de m√©thanisation (biogaz), en utilisant **Azure Event Hub** comme point d'entr√©e central. Vous comparerez les deux approches d'ingestion dans Fabric, puis exploiterez les donn√©es avec des requ√™tes KQL progressives.

R√©sultat attendu : deux tables aliment√©es par le m√™me Event Hub via deux chemins diff√©rents, une ma√Ætrise des deux architectures, un Real-Time Dashboard et des alertes Activator.

---

## Contexte m√©tier : la centrale de m√©thanisation de Jendouba

La **centrale biogaz de Jendouba** (nord-ouest tunisien) valorise les d√©chets agricoles (r√©sidus d'oliviers, fumier, d√©chets de c√©r√©ales) pour produire du biogaz converti en √©lectricit√©. L'installation comprend :

- **2 digesteurs** (cuves de fermentation ana√©robie)
- **4 capteurs par digesteur** remontant des donn√©es toutes les 5 secondes
- **1 moteur de cog√©n√©ration** qui convertit le biogaz en √©lectricit√© et chaleur

| Capteur            | Signification                         | Unit√© | Seuil critique                   |
| ------------------ | ------------------------------------- | ----- | -------------------------------- |
| **DigesteurTempC** | Temp√©rature du digesteur              | ¬∞C    | < 35 ou > 42 (zone m√©sophile)    |
| **pH**             | Acidit√© du substrat                   | -     | < 6.5 ou > 7.8                   |
| **BiogasFlowM3h**  | D√©bit de biogaz produit               | m¬≥/h  | < 50 (sous-production)           |
| **MethanePct**     | Pourcentage de m√©thane dans le biogaz | %     | < 50 (biogaz inutilisable)       |
| **CO2Pct**         | Pourcentage de CO2                    | %     | > 45 (fermentation perturb√©e)    |
| **H2SPpm**         | Hydrog√®ne sulfur√© (gaz toxique)       | ppm   | > 500 (danger sant√© + corrosion) |
| **PowerOutputKW**  | Puissance √©lectrique produite         | kW    | -                                |
| **SubstrateLevel** | Niveau de substrat dans le digesteur  | %     | < 20 (alimentation insuffisante) |

**Probl√®mes r√©els rencontr√©s par les exploitants biogaz :**

- Acidification du digesteur (chute de pH) ‚Üí arr√™t de la production de m√©thane pendant des jours
- Pic de H2S qui corrode les √©quipements et met en danger le personnel
- Temp√©rature instable qui ralentit la m√©thanog√©n√®se sans que personne ne s'en aper√ßoive
- Moteur de cog√©n√©ration aliment√© avec du biogaz pauvre en m√©thane (< 50%) ‚Üí panne moteur
- Pas de visibilit√© centralis√©e : l'op√©rateur fait des rondes physiques toutes les 4 heures

---

## Les deux approches d'ingestion : pourquoi les comparer ?

|                      | Approche A                                 | Approche B                                   |
| -------------------- | ------------------------------------------ | -------------------------------------------- |
| **Chemin**           | Event Hub ‚Üí **Eventstream** ‚Üí KQL Database | Event Hub ‚Üí **KQL Database** (direct)        |
| **Transformations**  | Oui (no-code dans Eventstream)             | Non (transformation en KQL apr√®s ingestion)  |
| **Quand l'utiliser** | Donn√©es √† nettoyer/enrichir avant stockage | Donn√©es d√©j√† propres, ingestion brute rapide |
| **Latence**          | Quelques secondes de plus                  | Minimale                                     |
| **Complexit√©**       | Plus de composants √† g√©rer                 | Plus simple, moins de composants             |
| **Table cible**      | `BiogasEventsStream`                       | `BiogasEventsDirect`                         |

Dans cet atelier, le **m√™me simulateur Python** envoie au **m√™me Event Hub Azure**, et les donn√©es arrivent dans **deux tables diff√©rentes** via les deux chemins.

---

## Pr√©requis

- **Abonnement Azure** (gratuit suffit) pour cr√©er un Event Hub
- Tenant **Microsoft Fabric** (licence Trial ou Capacity, minimum F4)
- **Python 3.9+** install√©
- Package Python : `azure-eventhub`

---

## Partie 1 ‚Äî Cr√©er l'Event Hub dans Azure

### 1.1 ‚Äî Cr√©er le namespace Event Hub

1. Aller sur **portal.azure.com**
2. Cliquer **+ Create a resource**
3. Chercher **Event Hubs** ‚Üí cliquer **Create**
4. Remplir :

| Champ              | Valeur                                            |
| ------------------ | ------------------------------------------------- |
| **Subscription**   | Votre abonnement                                  |
| **Resource group** | Cr√©er nouveau : `rg-biogaz`                       |
| **Namespace name** | `eh-biogaz-jendouba` (doit √™tre unique)           |
| **Location**       | La plus proche (ex: France Central, North Europe) |
| **Pricing tier**   | `Basic` (suffisant pour l'atelier)                |

5. Cliquer **Review + create** ‚Üí **Create**
6. Attendre le d√©ploiement ‚Üí cliquer **Go to resource**

### 1.2 ‚Äî Cr√©er l'Event Hub instance

1. Dans le namespace, cliquer **+ Event Hub** (barre du haut)
2. Nom : **`biogaz-telemetry`**
3. **Partition count** : `2` (suffisant)
4. Cliquer **Create**

### 1.3 ‚Äî Cr√©er la SAS Policy et r√©cup√©rer les cl√©s

1. Cliquer sur l'Event Hub **biogaz-telemetry** (dans la liste)
2. Dans le menu gauche ‚Üí **Shared access policies**
3. Cliquer **+ Add**
4. Nom : **`fabricpolicy`**
5. Cocher ‚úÖ **Manage** (inclut Send et Listen)
6. Cliquer **Create**
7. Cliquer sur **fabricpolicy** dans la liste
8. Copier dans un **bloc-notes** :

| Valeur                            | Usage                                  |
| --------------------------------- | -------------------------------------- |
| **Primary key**                   | Pour la connexion directe KQL Database |
| **Connection string‚Äìprimary key** | Pour le script Python ET Eventstream   |

> ‚ö†Ô∏è **Pi√®ge** : Copiez la **Connection string** de la policy **fabricpolicy** sur l'Event Hub instance, pas celle du namespace. Les deux existent mais n'ont pas les m√™mes droits.

> üí° **Astuce** : Notez aussi le **nom du namespace** (`eh-biogaz-jendouba`) et le **nom de l'Event Hub** (`biogaz-telemetry`). Vous en aurez besoin √† plusieurs reprises.

---

## Partie 2 ‚Äî Cr√©er l'Eventhouse dans Fabric

1. Aller sur **app.fabric.microsoft.com** ‚Üí votre **workspace**
2. Cliquer **+ New item** ‚Üí **Eventhouse**
3. Nom : **`BiogasEventhouse`**
4. Cliquer **Create**

> Un KQL Database `BiogasEventhouse` est automatiquement cr√©√©.

---

## Partie 3 ‚Äî Approche A : Event Hub ‚Üí Eventstream ‚Üí KQL Database

### 3.1 ‚Äî Cr√©er l'Eventstream

1. Dans votre workspace ‚Üí **+ New item** ‚Üí **Eventstream**
2. Nom : **`BiogasEventstream`**
3. Cliquer **Create**

### 3.2 ‚Äî Connecter l'Event Hub comme source

1. Cliquer **Use external source** (ou **Add source** ‚Üí **External sources**)
2. Chercher **Azure Event Hubs** ‚Üí cliquer **Connect**
3. S√©lectionner **New connection**
4. Remplir :

| Champ                      | Valeur                                                         |
| -------------------------- | -------------------------------------------------------------- |
| **Event Hub namespace**    | `eh-biogaz-jendouba` (le nom du namespace, PAS l'URL compl√®te) |
| **Event Hub**              | `biogaz-telemetry`                                             |
| **Shared Access Key Name** | `fabricpolicy`                                                 |
| **Shared Access Key**      | Coller la **Primary key** copi√©e en 1.3                        |

5. Cliquer **Connect**
6. **Consumer group** : laisser `$Default`
7. Cliquer **Next**
8. **Schema handling** : s√©lectionner **Fixed schema**
9. Cliquer **Connect**

### 3.3 ‚Äî Ajouter la destination Eventhouse

1. Cliquer **Edit** (si pas d√©j√† en mode √©dition)
2. Cliquer le bloc **"Transform events or add destination"**
3. S√©lectionner **Eventhouse**
4. Remplir :

| Champ                     | Valeur                                      |
| ------------------------- | ------------------------------------------- |
| **Data ingestion mode**   | `Event processing before ingestion`         |
| **Destination name**      | `BiogasStreamDest`                          |
| **Workspace**             | Votre workspace                             |
| **Eventhouse**            | `BiogasEventhouse`                          |
| **KQL Database**          | `BiogasEventhouse`                          |
| **KQL Destination table** | Taper `BiogasEventsStream` ‚Üí **Create new** |
| **Input data format**     | `Json`                                      |

5. Cocher ‚úÖ **Activate ingestion after adding the data source**
6. Cliquer **Save** ‚Üí **Publish**

---

## Partie 4 ‚Äî Approche B : Event Hub ‚Üí KQL Database (ingestion directe)

### 4.1 ‚Äî Configurer la connexion directe

1. Aller dans votre **workspace** ‚Üí cliquer sur **BiogasEventhouse**
2. Dans le panneau gauche ‚Üí cliquer sur la KQL Database **BiogasEventhouse**
3. Cliquer **Get data** (barre du haut)
4. S√©lectionner **Event Hubs**
5. **Table** : cliquer **+ New table** ‚Üí nom : **`BiogasEventsDirect`**
6. Cliquer **Next**

### 4.2 ‚Äî Configurer la connexion

1. S√©lectionner **Create new connection**
2. Remplir :

| Champ                      | Valeur                                      |
| -------------------------- | ------------------------------------------- |
| **Event Hub namespace**    | `eh-biogaz-jendouba.servicebus.windows.net` |
| **Event Hub**              | `biogaz-telemetry`                          |
| **Connection name**        | `biogaz-direct-connection`                  |
| **Authentication kind**    | `Shared Access Key`                         |
| **Shared Access Key Name** | `fabricpolicy`                              |
| **Shared Access Key**      | Coller la **Primary key**                   |

3. Cliquer **Save**
4. **Consumer group** : s√©lectionner `$Default`
5. Cliquer **Next**
6. Fabric affiche un aper√ßu des donn√©es (si le simulateur tourne d√©j√†) ‚Üí v√©rifier le mapping des colonnes
7. Cliquer **Finish**

> üí° **Astuce** : Pour l'approche B, Fabric cr√©e une **data connection** permanente. Tant que l'Event Hub re√ßoit des donn√©es, la table `BiogasEventsDirect` est aliment√©e automatiquement, sans Eventstream interm√©diaire.

> ‚ö†Ô∏è **Pi√®ge** : Pour le namespace dans l'approche B, il faut ajouter `.servicebus.windows.net` √† la fin. Dans l'approche A (Eventstream), le nom seul suffit.

---

## Partie 5 ‚Äî Le simulateur Python

### 5.1 ‚Äî Installer le package

```bash
pip install azure-eventhub
```

### 5.2 ‚Äî Cr√©er le script

Cr√©er un fichier **`biogas_simulator.py`** :

```python
import json
import time
import random
from datetime import datetime, timezone
from azure.eventhub import EventHubProducerClient, EventData

# ============================================================
# CONFIGURATION ‚Äî Connection string de l'Event Hub Azure
# (PAS celle de l'Eventstream Fabric, celle du portail Azure)
# ============================================================
CONNECTION_STR = "<connection_string_primary_key_de_fabricpolicy>"
EVENTHUB_NAME = "biogaz-telemetry"
# ============================================================

DIGESTERS = ["DIG-001", "DIG-002"]
PLANT_NAME = "Centrale Biogaz Jendouba"

def generate_biogas_event(digester_id):
    # Temperature digesteur (zone mesophile optimale : 37-40¬∞C)
    base_temp = 38.5
    temp = base_temp + random.uniform(-2.5, 2.5)

    # pH (optimal : 6.8 - 7.4)
    ph = 7.1 + random.uniform(-0.4, 0.4)

    # Debit biogaz (m3/h)
    biogas_flow = random.uniform(80, 200)

    # Composition du biogaz
    methane_pct = random.uniform(55, 68)
    co2_pct = random.uniform(28, 40)
    h2s_ppm = random.uniform(50, 300)

    # Puissance electrique (proportionnelle au debit * methane)
    power = biogas_flow * (methane_pct / 100) * 2.5 + random.uniform(-20, 20)

    # Niveau substrat
    substrate_level = random.uniform(30, 85)

    # ==========================================
    # INJECTION D'ANOMALIES (12% du temps)
    # ==========================================
    anomaly = "None"
    if random.random() < 0.12:
        anomaly_type = random.choice([
            "acidification",     # Chute de pH
            "temperature_drop",  # Chute de temperature
            "h2s_spike",         # Pic H2S dangereux
            "low_methane",       # Biogaz pauvre
            "substrate_low",     # Manque de substrat
            "overload"           # Surcharge organique
        ])
        if anomaly_type == "acidification":
            ph -= random.uniform(0.8, 1.5)
            methane_pct *= 0.6
            biogas_flow *= 0.5
            anomaly = "acidification"
        elif anomaly_type == "temperature_drop":
            temp -= random.uniform(5, 10)
            biogas_flow *= 0.7
            anomaly = "temperature_drop"
        elif anomaly_type == "h2s_spike":
            h2s_ppm += random.uniform(300, 800)
            anomaly = "h2s_spike"
        elif anomaly_type == "low_methane":
            methane_pct = random.uniform(35, 48)
            power *= 0.4
            anomaly = "low_methane"
        elif anomaly_type == "substrate_low":
            substrate_level = random.uniform(5, 18)
            biogas_flow *= 0.6
            anomaly = "substrate_low"
        elif anomaly_type == "overload":
            ph -= random.uniform(0.5, 1.0)
            co2_pct += random.uniform(5, 15)
            h2s_ppm += random.uniform(100, 300)
            anomaly = "overload"

        # Recalcul puissance apres anomalie
        power = biogas_flow * (methane_pct / 100) * 2.5 + random.uniform(-20, 20)

    return {
        "DigesterId": digester_id,
        "Timestamp": datetime.now(timezone.utc).isoformat(),
        "DigesteurTempC": round(temp, 2),
        "pH": round(max(4.0, ph), 2),
        "BiogasFlowM3h": round(max(0, biogas_flow), 2),
        "MethanePct": round(max(0, methane_pct), 2),
        "CO2Pct": round(min(60, max(0, co2_pct)), 2),
        "H2SPpm": round(max(0, h2s_ppm), 1),
        "PowerOutputKW": round(max(0, power), 2),
        "SubstrateLevel": round(max(0, min(100, substrate_level)), 1),
        "Anomaly": anomaly,
        "PlantName": PLANT_NAME
    }

def main():
    producer = EventHubProducerClient.from_connection_string(
        conn_str=CONNECTION_STR,
        eventhub_name=EVENTHUB_NAME
    )
    print("Envoi de telemetrie biogaz vers Azure Event Hub...")
    print(f"Event Hub: {EVENTHUB_NAME}")
    print(f"Les donnees arrivent dans Fabric via 2 chemins simultanement\n")

    try:
        while True:
            batch = producer.create_batch()
            for dig_id in DIGESTERS:
                event = generate_biogas_event(dig_id)
                batch.add(EventData(json.dumps(event)))
                status = f" *** {event['Anomaly'].upper()} ***" if event['Anomaly'] != "None" else ""
                print(f"  [{event['Timestamp'][:19]}] {dig_id} | "
                      f"Temp: {event['DigesteurTempC']}C | "
                      f"pH: {event['pH']} | "
                      f"CH4: {event['MethanePct']}% | "
                      f"H2S: {event['H2SPpm']}ppm | "
                      f"Puiss: {event['PowerOutputKW']}kW{status}")
            producer.send_batch(batch)
            print(f"  -> Batch de {len(DIGESTERS)} evenements envoye\n")
            time.sleep(5)
    except KeyboardInterrupt:
        print("Arret du simulateur.")
    finally:
        producer.close()

if __name__ == "__main__":
    main()
```

### 5.3 ‚Äî Configurer et lancer

1. Remplacer `<connection_string_primary_key_de_fabricpolicy>` par la **Connection string** copi√©e en 1.3
2. Sauvegarder
3. Lancer :

```bash
cd D:\msfabric
py biogas_simulator.py
```

**Output attendu :**

```
Envoi de telemetrie biogaz vers Azure Event Hub...
Event Hub: biogaz-telemetry
Les donnees arrivent dans Fabric via 2 chemins simultanement

  [2026-02-11T10:22:05] DIG-001 | Temp: 38.2C | pH: 7.03 | CH4: 62.5% | H2S: 185.3ppm | Puiss: 312.4kW
  [2026-02-11T10:22:05] DIG-002 | Temp: 33.1C | pH: 6.89 | CH4: 58.1% | H2S: 142.7ppm | Puiss: 287.6kW *** TEMPERATURE_DROP ***
  -> Batch de 2 evenements envoye
```

> üí° **Astuce** : Laissez tourner **au moins 5 minutes** avant les requ√™tes. Les donn√©es arrivent simultan√©ment dans les deux tables (`BiogasEventsStream` et `BiogasEventsDirect`).

---

## Partie 6 ‚Äî V√©rifier les deux tables

1. Dans Fabric ‚Üí **BiogasEventhouse** ‚Üí KQL Database
2. Sous **Tables**, vous devez voir **deux tables** :
   - `BiogasEventsStream` (aliment√©e via Eventstream ‚Äî Approche A)
   - `BiogasEventsDirect` (aliment√©e directement ‚Äî Approche B)
3. Cliquer sur chacune ‚Üí onglet **Data preview** ‚Üí v√©rifier que les donn√©es arrivent

> ‚ö†Ô∏è **Pi√®ge espace** : Si le nom d'une table a un espace √† la fin, utilisez `['BiogasEventsStream ']` dans les requ√™tes KQL. Testez sans crochets d'abord.

---

## Partie 7 ‚Äî 15 requ√™tes KQL progressives

Aller dans **BiogasEventhouse_queryset**.

> **Convention** : Les requ√™tes utilisent `BiogasEventsStream`. Adaptez le nom si n√©cessaire.

---

### üîπ NIVEAU D√âBUTANT

---

### Requ√™te 1 ‚Äî `take` : Premier contact

**Probl√®me terrain** : Le technicien vient de brancher les capteurs. Il veut v√©rifier que tout remonte.

**Question m√©tier** : Les donn√©es arrivent-elles ? √Ä quoi ressemblent-elles ?

```kql
BiogasEventsStream
| take 10
```

**Interpr√©tation** : 10 lignes brutes. V√©rifiez que le Timestamp est r√©cent, que DigesterId a bien deux valeurs (DIG-001, DIG-002), et que les mesures sont dans les plages attendues. Si le Timestamp est vieux de plusieurs minutes, le pipeline a un retard.

---

### Requ√™te 2 ‚Äî Comparer les deux tables : m√™me source, deux chemins

**Probl√®me terrain** : Le responsable IT veut v√©rifier que les deux pipelines fonctionnent et qu'ils re√ßoivent le m√™me volume de donn√©es.

**Question m√©tier** : Les deux approches d'ingestion sont-elles synchronis√©es ?

```kql
let stream_count = BiogasEventsStream | where Timestamp > ago(10m) | count | extend Source = "Approche A (Eventstream)";
let direct_count = BiogasEventsDirect | where Timestamp > ago(10m) | count | extend Source = "Approche B (Direct)";
stream_count
| union direct_count
```

**Interpr√©tation** : Les deux comptes doivent √™tre proches. Un √©cart important signifie qu'un des deux pipelines a un retard ou une perte. L'Approche B (directe) a g√©n√©ralement un l√©ger avantage en latence car il n'y a pas d'Eventstream interm√©diaire.

---

### Requ√™te 3 ‚Äî `where` : Filtrer les situations dangereuses (H2S)

**Probl√®me terrain** : L'hydrog√®ne sulfur√© (H2S) au-dessus de 500 ppm est dangereux pour le personnel et corrode les √©quipements. Le responsable s√©curit√© doit savoir imm√©diatement si ce seuil a √©t√© franchi.

**Question m√©tier** : Y a-t-il eu des pics de H2S dangereux dans la derni√®re heure ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| where H2SPpm > 500
| project Timestamp, DigesterId, H2SPpm, pH, Anomaly
| order by H2SPpm desc
```

**Interpr√©tation** : Chaque ligne est un **incident de s√©curit√©**. Un H2S > 500 ppm ‚Üí √©vacuation de la zone, arr√™t du digesteur, ventilation forc√©e. Si ces pics sont corr√©l√©s √† une chute de pH (colonne pH < 6.5), la cause est une acidification ‚Üí il faut ajouter de la chaux pour remonter le pH avant de red√©marrer.

---

### Requ√™te 4 ‚Äî `project` + `extend` : Le digesteur est-il en zone optimale ?

**Probl√®me terrain** : Un digesteur m√©sophile fonctionne entre 35¬∞C et 42¬∞C, avec un pH entre 6.5 et 7.8. En dehors de ces plages, les bact√©ries ralentissent et la production chute. L'op√©rateur veut savoir en un coup d'≈ìil si chaque mesure est dans la norme.

**Question m√©tier** : Chaque param√®tre est-il dans sa zone optimale ?

```kql
BiogasEventsStream
| where Timestamp > ago(10m)
| extend TempStatus = iff(DigesteurTempC between (35.0 .. 42.0), "OK", "HORS ZONE")
| extend pHStatus = iff(pH between (6.5 .. 7.8), "OK", "HORS ZONE")
| extend H2SStatus = iff(H2SPpm < 500, "OK", "DANGER")
| extend MethaneStatus = iff(MethanePct > 50, "OK", "PAUVRE")
| project Timestamp, DigesterId, DigesteurTempC, TempStatus, pH, pHStatus, H2SPpm, H2SStatus, MethanePct, MethaneStatus
| order by Timestamp desc
```

**Interpr√©tation** : L'op√©rateur ne regarde que les colonnes "Status". Tout ce qui n'est pas "OK" n√©cessite une action. C'est le principe du management par exception : on ne traite que ce qui d√©vie de la norme. √áa remplace la ronde physique de 4 heures par un √©cran consult√© en 10 secondes.

---

### Requ√™te 5 ‚Äî `summarize` + `countif` : Bilan des anomalies par digesteur

**Probl√®me terrain** : Le directeur technique pr√©pare le rapport hebdomadaire. Il veut savoir quel digesteur pose le plus de probl√®mes et quel type d'anomalie domine.

**Question m√©tier** : Quelle est la r√©partition des anomalies par digesteur et par type ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| where Anomaly != "None"
| summarize
    Acidification = countif(Anomaly == "acidification"),
    TempDrop = countif(Anomaly == "temperature_drop"),
    H2SSpike = countif(Anomaly == "h2s_spike"),
    LowMethane = countif(Anomaly == "low_methane"),
    SubstrateLow = countif(Anomaly == "substrate_low"),
    Overload = countif(Anomaly == "overload"),
    Total = count()
  by DigesterId
```

**Interpr√©tation** : Si DIG-001 a 8 acidifications et 0 pour les autres types ‚Üí le probl√®me est cibl√© et la solution est claire (ajout de tampon alcalin). Si DIG-002 a des anomalies diversifi√©es ‚Üí le probl√®me est syst√©mique (substrat de mauvaise qualit√©, √©quipement vieillissant). Le rapport oriente le budget : r√©paration cibl√©e vs remplacement complet.

---

### Requ√™te 6 ‚Äî `bin()` + `ago()` : √âvolution de la production toutes les 5 minutes

**Probl√®me terrain** : Le gestionnaire du r√©seau √©lectrique demande un profil de production horaire pour planifier l'int√©gration au r√©seau.

**Question m√©tier** : Comment √©volue la puissance totale produite par tranche de 5 minutes ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize
    TotalPowerKW = round(sum(PowerOutputKW), 1),
    AvgMethane = round(avg(MethanePct), 1),
    AvgpH = round(avg(pH), 2),
    NbAnomalies = countif(Anomaly != "None")
  by bin(Timestamp, 5m)
| order by Timestamp asc
```

**Interpr√©tation** : La puissance totale doit √™tre stable pour un digesteur continu. Une chute brutale corr√©l√©e √† une baisse de MethanePct = le biogaz est devenu trop pauvre pour le moteur. Une chute corr√©l√©e √† une baisse de pH = acidification en cours. La corr√©lation entre les colonnes raconte l'histoire de l'incident.

---

### Requ√™te 7 ‚Äî `arg_max` : Trouver le pire pic de H2S avec son contexte

**Probl√®me terrain** : Le responsable HSE (Hygi√®ne S√©curit√© Environnement) doit documenter le pire incident H2S de l'heure pour le registre de s√©curit√©.

**Question m√©tier** : Quel a √©t√© le pic H2S le plus √©lev√©, avec toutes les conditions √† ce moment-l√† ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize arg_max(H2SPpm, Timestamp, DigesterId, pH, DigesteurTempC, BiogasFlowM3h, Anomaly)
```

**Interpr√©tation** : `arg_max` retourne la ligne compl√®te du pire moment. Le responsable HSE voit : "Pic √† 847 ppm sur DIG-002 √† 14h23, pH √©tait √† 5.9, anomalie = acidification". Il sait que le H2S est une cons√©quence de l'acidification et peut documenter la cha√Æne causale dans le registre de s√©curit√©.

---

### üîπ NIVEAU INTERM√âDIAIRE

---

### Requ√™te 8 ‚Äî `percentile` : Variabilit√© de la qualit√© du biogaz

**Probl√®me terrain** : Le moteur de cog√©n√©ration tol√®re un m√©thane entre 50% et 70%. Les moyennes masquent les creux. L'ing√©nieur process veut voir les percentiles pour √©valuer la stabilit√©.

**Question m√©tier** : Quelle est la variabilit√© du taux de m√©thane par digesteur ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize
    P5 = round(percentile(MethanePct, 5), 1),
    P25 = round(percentile(MethanePct, 25), 1),
    P50 = round(percentile(MethanePct, 50), 1),
    P75 = round(percentile(MethanePct, 75), 1),
    P95 = round(percentile(MethanePct, 95), 1),
    Moyenne = round(avg(MethanePct), 1)
  by DigesterId
| extend Stabilite = round(P95 - P5, 1)
```

**Interpr√©tation** : Un digesteur avec P5=42% et P95=65% (stabilit√©=23) est erratique : il envoie r√©guli√®rement du biogaz inutilisable au moteur. Un digesteur avec P5=56% et P95=66% (stabilit√©=10) est fiable. L'√©cart P5-P95 est l'indicateur cl√© pour d√©cider s'il faut investir dans un ballon tampon de stockage du biogaz pour lisser les variations.

---

### Requ√™te 9 ‚Äî `prev()` : D√©tecter les chutes brutales de pH

**Probl√®me terrain** : L'acidification ne survient pas d'un coup ‚Äî elle s'installe progressivement. Mais une chute de pH de plus de 0.3 en un seul intervalle est un signal d'alarme.

**Question m√©tier** : Y a-t-il eu des chutes brutales de pH ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| order by DigesterId, Timestamp asc
| extend PrevpH = prev(pH, 1)
| extend PrevDigester = prev(DigesterId, 1)
| where DigesterId == PrevDigester
| where PrevpH > 0
| extend pHDrop = round(PrevpH - pH, 3)
| where pHDrop > 0.3
| project Timestamp, DigesterId, PrevpH, pH, pHDrop, BiogasFlowM3h, Anomaly
| order by pHDrop desc
```

**Interpr√©tation** : Une chute de 0.3+ de pH en 5 secondes n'est pas une d√©rive lente ‚Äî c'est un √©v√©nement soudain : injection d'un substrat trop acide, ou d√©faillance du syst√®me de r√©gulation. L'op√©rateur doit imm√©diatement v√©rifier le dernier chargement de substrat et le syst√®me de dosage de chaux.

---

### Requ√™te 10 ‚Äî `join` : Croiser avec les sp√©cifications techniques

**Probl√®me terrain** : Chaque digesteur a une capacit√© nominale diff√©rente. L'exploitant veut comparer la production r√©elle vs la capacit√© install√©e.

**Question m√©tier** : Quel est le taux d'utilisation de chaque digesteur ?

```kql
let DigesterSpecs = datatable(DigesterId: string, NominalPowerKW: int, VolumeM3: int, CommissionDate: string) [
    "DIG-001", 400, 2500, "2021-06-15",
    "DIG-002", 350, 2000, "2022-09-01"
];
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize AvgPower = avg(PowerOutputKW), AvgFlow = avg(BiogasFlowM3h) by DigesterId
| join kind=inner DigesterSpecs on DigesterId
| extend UtilizationPct = round(AvgPower / NominalPowerKW * 100, 1)
| project DigesterId, round(AvgPower, 1), NominalPowerKW, UtilizationPct, round(AvgFlow, 1), VolumeM3, CommissionDate
| order by UtilizationPct desc
```

**Interpr√©tation** : Un taux d'utilisation de 60% signifie que 40% de la capacit√© install√©e est gaspill√©e. Si DIG-001 (2021) est √† 75% et DIG-002 (2022) est √† 55%, le probl√®me n'est pas l'√¢ge mais probablement l'alimentation en substrat ou un d√©s√©quilibre biologique. L'exploitant sait o√π concentrer ses efforts d'optimisation.

---

### Requ√™te 11 ‚Äî `union` : Vue consolid√©e des deux tables

**Probl√®me terrain** : Le responsable IT veut v√©rifier la coh√©rence entre les deux pipelines en comparant les donn√©es ligne par ligne.

**Question m√©tier** : Les deux chemins d'ingestion produisent-ils des donn√©es identiques ?

```kql
let StreamData = BiogasEventsStream
    | where Timestamp > ago(5m)
    | summarize StreamCount = count(), StreamAvgPower = round(avg(PowerOutputKW), 1) by DigesterId;
let DirectData = BiogasEventsDirect
    | where Timestamp > ago(5m)
    | summarize DirectCount = count(), DirectAvgPower = round(avg(PowerOutputKW), 1) by DigesterId;
StreamData
| join kind=inner DirectData on DigesterId
| extend CountDiff = StreamCount - DirectCount
| extend PowerDiff = round(StreamAvgPower - DirectAvgPower, 2)
| project DigesterId, StreamCount, DirectCount, CountDiff, StreamAvgPower, DirectAvgPower, PowerDiff
```

**Interpr√©tation** : Si CountDiff est proche de 0 et PowerDiff est quasi-nul, les deux pipelines sont √©quivalents. Si l'approche directe a syst√©matiquement plus de lignes, l'Eventstream introduit un l√©ger retard. Ce test valide que les deux architectures sont interchangeables pour votre cas d'usage, ce qui est crucial avant de choisir celle que vous mettez en production.

---

### Requ√™te 12 ‚Äî `make_series` + `render` : Courbe de tendance du pH

**Probl√®me terrain** : L'ing√©nieur process veut voir la tendance du pH sur l'heure pass√©e pour chaque digesteur, pas juste les valeurs ponctuelles.

**Question m√©tier** : Le pH est-il stable, en baisse ou en hausse ?

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize AvgpH = round(avg(pH), 2) by DigesterId, bin(Timestamp, 2m)
| order by Timestamp asc
| render timechart with (title="Evolution du pH par digesteur")
```

**Interpr√©tation** : Un pH en baisse constante, m√™me s'il est encore dans la zone verte (> 6.5), est un signal pr√©dictif d'acidification imminente. Attendre qu'il passe sous 6.5 pour agir, c'est trop tard ‚Äî la r√©cup√©ration prend des jours. La tendance est plus importante que la valeur absolue.

---

### Requ√™te 13 ‚Äî `case` : Classification du risque op√©rationnel

**Probl√®me terrain** : Le directeur veut un tableau simple rouge/orange/vert pour le briefing du matin.

**Question m√©tier** : Quel est l'√©tat de chaque digesteur en ce moment ?

```kql
BiogasEventsStream
| where Timestamp > ago(15m)
| summarize
    AvgTemp = avg(DigesteurTempC),
    MinpH = min(pH),
    AvgpH = avg(pH),
    MaxH2S = max(H2SPpm),
    AvgMethane = avg(MethanePct),
    AvgPower = avg(PowerOutputKW),
    AvgSubstrate = avg(SubstrateLevel),
    NbAnomalies = countif(Anomaly != "None"),
    Events = count()
  by DigesterId
| extend TempRisk = case(AvgTemp < 35 or AvgTemp > 42, "ROUGE", AvgTemp < 36 or AvgTemp > 41, "ORANGE", "VERT")
| extend pHRisk = case(MinpH < 6.0, "ROUGE", MinpH < 6.5, "ORANGE", "VERT")
| extend H2SRisk = case(MaxH2S > 700, "ROUGE", MaxH2S > 500, "ORANGE", "VERT")
| extend MethaneRisk = case(AvgMethane < 45, "ROUGE", AvgMethane < 50, "ORANGE", "VERT")
| extend GlobalRisk = case(
    TempRisk == "ROUGE" or pHRisk == "ROUGE" or H2SRisk == "ROUGE", "ARRET IMMEDIAT",
    TempRisk == "ORANGE" or pHRisk == "ORANGE" or H2SRisk == "ORANGE" or MethaneRisk == "ORANGE", "SURVEILLANCE RENFORCEE",
    "FONCTIONNEMENT NORMAL")
| project DigesterId, GlobalRisk, TempRisk, round(AvgTemp, 1), pHRisk, round(AvgpH, 2), H2SRisk, round(MaxH2S, 0), MethaneRisk, round(AvgMethane, 1), round(AvgPower, 1)
| order by GlobalRisk asc
```

**Interpr√©tation** : Ce tableau est le **cockpit du matin**. "ARRET IMMEDIAT" ‚Üí le directeur appelle imm√©diatement l'√©quipe technique. "SURVEILLANCE RENFORCEE" ‚Üí passage en rondes toutes les heures au lieu de 4 heures. "FONCTIONNEMENT NORMAL" ‚Üí on continue. 30 secondes de lecture remplacent 1 heure de tour de terrain.

---

### Requ√™te 14 ‚Äî `dcount` + `make_set` : V√©rifier la compl√©tude des donn√©es

**Probl√®me terrain** : Apr√®s une coupure de courant, le responsable IT veut v√©rifier que tous les capteurs ont repris la communication.

**Question m√©tier** : Tous les digesteurs communiquent-ils ? Quels types d'anomalies sont apparus ?

```kql
BiogasEventsStream
| where Timestamp > ago(10m)
| summarize
    DigesteursActifs = dcount(DigesterId),
    ListeDigesteurs = make_set(DigesterId),
    TypesAnomalies = make_set(Anomaly),
    DernierMessage = max(Timestamp),
    NbMessages = count()
```

**Interpr√©tation** : On attend 2 digesteurs actifs. Si DigesteursActifs = 1, un digesteur est muet ‚Üí v√©rification imm√©diate. `make_set(Anomaly)` montre la diversit√© des probl√®mes en un regard. Si la liste contient ["acidification", "h2s_spike", "overload"], la situation est multi-factorielle et n√©cessite une intervention coordonn√©e.

---

### Requ√™te 15 ‚Äî Tableau de synth√®se op√©rationnel complet

**Probl√®me terrain** : Le directeur d'exploitation doit envoyer un rapport en temps r√©el aux investisseurs et au gestionnaire du r√©seau.

**Question m√©tier** : Donnez-moi LE tableau qui r√©sume tout en une vue.

```kql
BiogasEventsStream
| where Timestamp > ago(30m)
| summarize
    AvgTemp = avg(DigesteurTempC),
    MinTemp = min(DigesteurTempC),
    MaxTemp = max(DigesteurTempC),
    AvgpH = avg(pH),
    MinpH = min(pH),
    AvgMethane = avg(MethanePct),
    MinMethane = min(MethanePct),
    AvgBiogasFlow = avg(BiogasFlowM3h),
    MaxH2S = max(H2SPpm),
    AvgPower = avg(PowerOutputKW),
    MaxPower = max(PowerOutputKW),
    AvgSubstrate = avg(SubstrateLevel),
    TotalAnomalies = countif(Anomaly != "None"),
    Acidifications = countif(Anomaly == "acidification"),
    H2SSpikes = countif(Anomaly == "h2s_spike"),
    Events = count()
  by DigesterId
| extend HealthScore = case(
    MinpH < 6.0 or MaxH2S > 700, 0,
    MinpH < 6.5 or MaxH2S > 500 or MinTemp < 33, 25,
    TotalAnomalies > 5, 50,
    AvgMethane < 50 or AvgTemp < 36, 65,
    AvgMethane < 55, 80,
    100)
| extend Status = case(
    HealthScore == 0, "CRITIQUE",
    HealthScore <= 25, "DEGRADE",
    HealthScore <= 50, "INSTABLE",
    HealthScore <= 65, "SOUS-OPTIMAL",
    HealthScore <= 80, "ACCEPTABLE",
    "OPTIMAL")
| project
    DigesterId, Status, HealthScore,
    Temp = strcat(round(AvgTemp, 1), "C [", round(MinTemp, 1), "-", round(MaxTemp, 1), "]"),
    pH = strcat(round(AvgpH, 2), " [min:", round(MinpH, 2), "]"),
    Methane = strcat(round(AvgMethane, 1), "% [min:", round(MinMethane, 1), "]"),
    H2S_max = strcat(round(MaxH2S, 0), " ppm"),
    Power = strcat(round(AvgPower, 0), " kW"),
    Anomalies = strcat(TotalAnomalies, " (Acid:", Acidifications, " H2S:", H2SSpikes, ")")
| order by HealthScore asc
```

**Interpr√©tation** : Ce tableau est le **rapport ex√©cutif**. Le directeur lit de haut en bas : les digesteurs les plus critiques en premier. Chaque colonne montre la moyenne ET la plage [min-max], ce qui r√©v√®le la volatilit√©. Le HealthScore chiffre objectivement la sant√© : un investisseur comprend "Score 25/100" mieux que "pH √† 6.3 avec H2S √† 620 ppm". Ce tableau est le livrable que l'op√©rateur biogaz vend √† ses partenaires pour prouver la fiabilit√© de son installation.

---

## Partie 8 ‚Äî Real-Time Dashboard

### 8.1 ‚Äî Tuile tableau de synth√®se

1. Dans le **queryset**, s√©lectionner la **requ√™te 15**
2. Cliquer **Save to Dashboard**
3. S√©lectionner **Create new dashboard**
4. Nom : **`Biogaz-LiveMonitoring`**
5. Nom de la tuile : **`Synthese operationnelle`**
6. Cliquer **Create** ‚Üí **Open dashboard**

### 8.2 ‚Äî Tuile courbe de pH

1. Cliquer **Manage** ‚Üí **+ Add tile**
2. Coller la **requ√™te 12** (render timechart du pH)
3. Le type **Line chart** s'applique automatiquement
4. Cliquer **Apply changes**

### 8.3 ‚Äî Tuile production √©lectrique

1. Cliquer **+ Add tile**
2. Coller :

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| summarize TotalPowerKW = sum(PowerOutputKW) by bin(Timestamp, 2m)
| render timechart with (title="Production electrique totale (kW)")
```

3. Cliquer **Apply changes**

### 8.4 ‚Äî Tuile r√©partition anomalies

1. Cliquer **+ Add tile**
2. Coller :

```kql
BiogasEventsStream
| where Timestamp > ago(1h)
| where Anomaly != "None"
| summarize Count = count() by Anomaly
| render piechart with (title="Repartition des anomalies")
```

3. Cliquer **Apply changes**

> üí° **Astuce** : **Manage** ‚Üí ‚öôÔ∏è ‚Üí **Auto refresh** ‚Üí **30 secondes**.

---

## Partie 9 ‚Äî Alertes Activator

1. Dans le dashboard, cliquer sur la tuile **courbe de pH** (8.2)
2. Cliquer **Set alert**
3. Configurer :

| Champ         | Valeur                 |
| ------------- | ---------------------- |
| **Measure**   | `AvgpH`                |
| **Condition** | Is less than           |
| **Value**     | `6.5`                  |
| **Action**    | Email ou Teams message |

4. Cliquer **Create**

> ‚ö†Ô∏è **Pi√®ge** : **Set alert** ne fonctionne que sur les tuiles de type **graphique**.

---

## Partie 10 ‚Äî Comparaison finale des deux approches

Apr√®s avoir travaill√© avec les deux tables, voici le bilan pratique :

| Crit√®re                       | Approche A (Eventstream)                 | Approche B (Directe)                  |
| ----------------------------- | ---------------------------------------- | ------------------------------------- |
| **Mise en place**             | Plus d'√©tapes (Eventstream + config)     | Moins d'√©tapes (Get Data dans KQL DB) |
| **Transformations in-flight** | Oui (filter, rename, group by)           | Non (tout en KQL apr√®s ingestion)     |
| **Latence observ√©e**          | Quelques secondes de plus                | Minimale                              |
| **Monitoring**                | Canvas visuel Eventstream                | Monitoring KQL Database               |
| **Multi-destination**         | Oui (Eventhouse + Lakehouse + Activator) | Non (une seule table cible)           |
| **Recommandation**            | Donn√©es √† transformer avant stockage     | Donn√©es propres, ingestion rapide     |

---

## Nettoyage

1. **Ctrl+C** dans le terminal pour arr√™ter le simulateur
2. Dans **Fabric** ‚Üí supprimer le dashboard, l'eventstream, l'eventhouse
3. Dans **Azure Portal** ‚Üí supprimer le resource group `rg-biogaz` (supprime le namespace Event Hub et tout son contenu)

> üí° **Astuce** : Supprimer le resource group Azure est le moyen le plus propre ‚Äî √ßa supprime tout en une seule action.
