# Atelier 1 : Ingestion dynamique multi-sources avec validation

## Contexte : Optimisation d'une cha√Æne d'approvisionnement en √©nergie renouvelable

Une **usine de production traditionnelle** d√©cide de migrer vers un mod√®le hybride solaire-√©olien. Les donn√©es √©nerg√©tiques proviennent de multiples capteurs et syst√®mes (consommation actuelle, production solaire, production √©olienne, stockage batteries).

### 1. √âtat des lieux

- **3 sources de donn√©es** quotidiennes :
  - `besoins_energetiques.csv` (consommation horaire de l'usine)
  - `production_solaire.csv` (rendement des panneaux par zone)
  - `production_eolienne.csv` (donn√©es des turbines)
- **D√©p√¥t non structur√©** : fichiers d√©pos√©s manuellement dans un dossier
- **Absence de validation** : impossible de savoir si toutes les sources sont arriv√©es
- **Processus manuel** : un technicien v√©rifie et importe les fichiers dans Excel

### 2. Probl√©matique

**Comment automatiser l'ingestion de donn√©es √©nerg√©tiques h√©t√©rog√®nes pour analyser les besoins actuels et identifier les sources renouvelables disponibles, sans intervention manuelle et avec validation de la compl√©tude ?**

Contraintes :

- ‚úÖ D√©tecter dynamiquement quels fichiers sont pr√©sents
- ‚úÖ Ignorer les fichiers non-CSV (logs techniques, images...)
- ‚úÖ Cr√©er une table Bronze par source √©nerg√©tique
- ‚úÖ Tracer les fichiers ing√©r√©s pour l'audit

### 3. Solution : Pipeline d'ingestion intelligent

Pipeline qui scanne, filtre, copie et trace automatiquement toutes les sources √©nerg√©tiques vers Bronze.

## √âtapes

### 1. Cr√©er le workspace

1. Ouvrez **Microsoft Fabric** : `https://app.fabric.microsoft.com`
2. Barre lat√©rale gauche ‚Üí cliquez sur **Workspaces**
3. Cliquez **+ New workspace**
4. Remplissez :
   - **Name** : `WS_Energie_Renouvelable`
   - **Description** : `Workspace pour optimisation cha√Æne approvisionnement √©nergie`
   - **Advanced** ‚Üí **License mode** : s√©lectionnez votre licence (Trial ou Premium)
5. Cliquez **Apply**

üí° **Astuce** : Le workspace est votre conteneur principal, tout sera cr√©√© dedans

---

### 2. Cr√©er le lakehouse Bronze

1. Dans le workspace **WS_Energie_Renouvelable**, cliquez **+ New item**
2. S√©lectionnez **Lakehouse**
3. **Name** : `LH_Energie_Bronze`
4. Cliquez **Create**

‚è≥ Attendez la cr√©ation (15-30 secondes)

---

### 3. Cr√©er le dossier landing et uploader les fichiers

1. Dans **LH_Energie_Bronze**, section **Explorer** (gauche)
2. Cliquez **Files** ‚Üí bouton **...** (3 points) ‚Üí **New subfolder**
3. **Folder name** : `landing`
4. Cliquez **Create**
5. Cliquez sur le dossier **landing** pour l'ouvrir
6. Cliquez **Upload** ‚Üí **Upload files**
7. S√©lectionnez les 3 fichiers CSV g√©n√©r√©s :
   - `besoins_energetiques.csv`
   - `production_solaire.csv`
   - `production_eolienne.csv`
8. Cliquez **Upload**

‚úÖ V√©rifiez que les 3 fichiers apparaissent dans `Files/landing/`

---

### 4. Cr√©er le pipeline

1. Cliquez sur le nom du workspace **WS_Energie_Renouvelable** (en haut √† gauche)
2. Cliquez **+ New item**
3. Recherchez et s√©lectionnez **Data pipeline**
4. **Name** : `PL_Ingestion_Energie_Bronze`
5. Cliquez **Create**

Le canvas du pipeline s'ouvre (zone blanche avec grille).

---

### 5. Cr√©er les variables du pipeline

1. En bas du canvas, cliquez sur l'onglet **Variables**
2. Cliquez **+ New** (3 fois pour cr√©er 3 variables)

**Variable 1** :

- **Name** : `FichiersTraites`
- **Type** : `Array`
- **Default value** : laissez vide

**Variable 2** :

- **Name** : `FichierActuel`
- **Type** : `String`
- **Default value** : laissez vide

**Variable 3** :

- **Name** : `NombreFichiers`
- **Type** : `Integer`
- **Default value** : `0`

üí° **Astuce** : Les variables permettent de stocker et tracer les informations pendant l'ex√©cution

---

### 6. Ajouter l'activit√© Get Metadata

1. Panneau **Activities** (gauche) ‚Üí section **General**

2. Glissez **Get Metadata** sur le canvas

3. Cliquez sur l'activit√© pour la s√©lectionner

4. En bas, onglet **General** :
   
   - **Name** : `ScanLanding`

5. Onglet **Settings** :
   
   - S√©l√©ctionner la connection  mon exemple **(Lakehouse formateur4 (Preview)**

6. - **Lakehouse** : s√©lectionnez `LH_Energie_Bronze`
   
   - Cliquez **Create**
   
   - **Root folder** : s√©lectionnez `Files`
   
   - Dans **File path** vous avez deux champs dans le premier vous mettez `landing` √† c√¥te du deuxi√®me, il y a une icone **Browse** cliquez l√†  et naviguer vers le fichier `besoins_energetiques.csv` 
   
   - Dans la propeir√©t√© **File format**  vous choisissez  **Delimited Text**
   
   - Observez que l'option **Preview data** devient active cliquez l√† pour visualiser les donn√©es

7. Retour sur **Settings** de **ScanLanding** :
   
   - **Field list** : cliquez **+ New**
   - Cochez **Child items**
   - Cliquez **OK**

üí° **Astuce** : Get Metadata avec Child items retourne la liste de tous les fichiers du dossier

---

### 7. Ajouter l'activit√© ForEach

1. **Activities** ‚Üí **Iteration & Conditionals**

2. Glissez **ForEach** sur le canvas (√† droite de ScanLanding)

3. Reliez **ScanLanding** √† **ForEach** :
   
   - Survolez **ScanLanding** ‚Üí petit carr√© vert appara√Æt
   - Cliquez et glissez vers **ForEach** (fl√®che verte se cr√©e)

4. Cliquez sur **ForEach**

5. Onglet **General** :
   
   - **Name** : `BouclerFichiers`

6. Onglet **Settings** :
   
   - **Items** : cliquez dans le champ ‚Üí **Add dynamic content**
   - Copiez-collez cette expression :
   
   ```
   @activity('ScanLanding').output.childItems
   ```
   
   - Cliquez **OK**

üí° **Astuce** : Cette expression r√©cup√®re le tableau des fichiers d√©tect√©s par Get Metadata

---

### 8. Ajouter l'activit√© If Condition (dans ForEach)

1. **Double-cliquez** sur l'activit√© **BouclerFichiers**
   
   - Une nouvelle zone de canvas s'ouvre (vous √™tes maintenant "√† l'int√©rieur" de la boucle)

2. **Activities** ‚Üí **Iteration & Conditionals**

3. Glissez **If Condition** sur ce canvas int√©rieur

4. Cliquez sur **If Condition**

5. Onglet **General** :
   
   - **Name** : `EstCSV`

6. Onglet **Activities** :
   
   - **Expression** : cliquez **Add dynamic content**
   - Copiez-collez :
   
   ```
   @endswith(item().name, '.csv')
   ```

üí° **Astuce** : `item()` repr√©sente l'√©l√©ment actuel de la boucle ForEach

‚ö†Ô∏è **Pi√®ge** : C'est `item()` sans `s`, pas `items()`

---

### 9. Configurer la branche True - Copy Data

1. Sur l'activit√© **EstCSV**, cliquez sur l'ic√¥ne **crayon** dans la section **True**
   - Une nouvelle zone s'ouvre (branche True)
2. **Activities** ‚Üí **Move & Transform**
3. Glissez **Copy data** sur ce canvas
4. Cliquez sur **Copy data**
5. Onglet **General** :
   - **Name** : `CopierVersBronze`

**Configuration Source** :

6. Onglet **Source** :
   
   - Selectionnez **Connection** et metter la connection exemple **(Lakehouse formateur4 (Preview)**
   - Dans **Lakehouse** selectionnez `LH_Energie_Bronze` dans le liste d√©roulante
   - Pour **Root folder** il y a deux options **Tables** et **Files** selectionnez **Files** 
   - En **File path type** selectionnez **List of files** 
   - En **Folder path**  mettez `landing`
   - Laisser la propri√©te **Path to file list** vide 
   - En **File format** choisissez **DelimitedText** 

7. Onglet **Destination**:
   
   - Selectionner la connetion **Lakehouse formateur4 (Preview) mon cas** 
   
   - En **Lakehouse** selectionner `LH_Energie_Bronze` 
   
   - En **Root folder** selectionner **Tables**
   
   - En **Table** dans le premier champ metter le sch√©ma de la table exemple **dbo** ou laisser vide, dans le deuxi√®me champ metter le focus une ligne verte  **Add dynamic content** s'affiche mettez l'expression `@replace(item().name, '.csv', '')` dans ce champ
   
   - Laisser le check box **Enter manually** coch√©e
   
   - En table action selectionnez **Append**
   
   - Laisser le check box Apply **V-Order** coch√©e 

8. On laisse les propri√©t√©s dans les onglets **Mapping** et **Settings** tel qu'ils son

9. Retour sur **Source** de **CopierVersBronze** :
   
   - **File path** ‚Üí cliquez sur l'ic√¥ne **Add dynamic content** (petit rectangle)
   - Dans **File path - Folder** : entrez `landing`
   - Dans **File path - File** : cliquez **Add dynamic content**
   - Copiez-collez :
   
   ```
   @item().name
   ```
   
   - Cliquez **OK**

10. Onglet **Destination**  :
- **Connection** : s√©lectionnez votre connexion `LH_Energie_Bronze` existante
- **Lakehouse** : s√©lectionnez `LH_Energie_Bronze`
- **Root folder** : s√©lectionnez **`Tables`** (pas Files)
11. **Table** :
    - **Cochez** la case **`Enter manually`**
    - Un champ texte appara√Æt
    - Cliquez sur l'ic√¥ne **Add dynamic content** (petit rectangle)
    - Copiez-collez :

```
    @replace(item().name, '.csv', '')
```

```
- Cliquez **OK**
```

13. **Table action** :
    
    - S√©lectionnez **`Append`** (ou `Overwrite` pour √©viter les doublons lors des tests)

14. **Apply V-Order** :
    
    Laissez coch√© ‚úÖ (optimisation automatique)

15. Onglets **Mapping** et **Settings** :
    
    Laissez toutes les valeurs par d√©faut
    
    - **Mapping** : Auto-d√©tection activ√©e
    - **Settings** : `Auto` pour tous les param√®tres

üí° **Astuce** : `replace()` enl√®ve `.csv` pour cr√©er `besoins_energetiques` au lieu de `besoins_energetiques.csv`

‚ö†Ô∏è **Important** : Il n'y a plus de "Dataset" √† cr√©er pour la destination dans l'interface actuelle. Tout se configure directement dans l'onglet **Destination**.

---

### 10. Ajouter Append Variable (tra√ßabilit√©)

1. Toujours dans la branche **True**, apr√®s **CopierVersBronze**

2. **Activities** ‚Üí **General** ‚Üí glissez **Append Variable**

3. Reliez **CopierVersBronze** ‚Üí **Append Variable** (fl√®che verte)

4. Cliquez sur **Append Variable**

5. Onglet **General** :
   
   - **Name** : `TracerFichier`

6. Onglet **Settings** :
   
   - **Name** : s√©lectionnez `FichiersTraites`
   - **Value** : cliquez **Add dynamic content**
   - Copiez-collez :
   
   ```
   @item().name
   ```
   
   - Cliquez **OK**

üí° **Astuce** : Append Variable ajoute chaque nom de fichier dans le tableau `FichiersTraites`

---

### 12. Retourner au canvas principal

1. En haut √† gauche, cliquez sur le fil d'Ariane : **PL_Ingestion_Energie_Bronze**
   - Vous revenez au canvas principal avec votre pipeline complet

---

### 13. Configurer ForEach

Le champ **Items** du **ForEach** est vide. Il faut y mettre l'expression dynamique.

1. Cliquez sur l'activit√© **BouclerFichiers** (ForEach)
2. Onglet **Settings** en bas
3. Dans le champ **Items**, cliquez sur **Add dynamic content**
4. Copiez-collez cette expression :

```
@activity('ScanLanding').output.childItems
```

5. Cliquez **OK**

### 13. Sauvegarder le pipeline

1. Cliquez **Save** (ic√¥ne disquette en haut)
2. Attendez la confirmation (‚úÖ en haut √† droite)

---

### 14. D√©boguer et tester le pipeline

1. Cliquez **Run** en haut de la page
2. Attendez l'ex√©cution (15-45 secondes)
3. Observez le **Output** :
   - **ScanLanding** : doit afficher `Succeeded` avec 3 items dans childItems
   - **BouclerFichiers** : 3 it√©rations visibles
   - **EstCSV** : 3√ó `Succeeded` (True branch)
   - **CopierVersBronze** : 3√ó `Succeeded`

üí° **Astuce** : Cliquez sur chaque activit√© dans Output pour voir les d√©tails (JSON)

‚ö†Ô∏è **Pi√®ge** : Si une activit√© √©choue, cliquez dessus pour voir l'erreur d√©taill√©e

---

### 15. Valider les tables Bronze cr√©√©es

1. Retournez au workspace **WS_Energie_Renouvelable**
2. Ouvrez **LH_Energie_Bronze**
3. Section **Tables** (gauche) :
   - ‚úÖ `besoins_energetiques` ‚Üí 168 lignes
   - ‚úÖ `production_solaire` ‚Üí 175 lignes
   - ‚úÖ `production_eolienne` ‚Üí 840 lignes
4. Cliquez sur une table pour pr√©visualiser les donn√©es

---

### 16. V√©rifier les variables (optionnel)

1. Retournez dans le pipeline **PL_Ingestion_Energie_Bronze**
2. Cliquez **Run** ‚Üí une fois termin√©, cliquez sur **BouclerFichiers** dans Output
3. Onglet **Variables** :
   - `FichiersTraites` : `["besoins_energetiques.csv", "production_solaire.csv", "production_eolienne.csv"]`
   - `NombreFichiers` : `3`

üí° **Astuce** : Les variables ne sont visibles qu'apr√®s ex√©cution compl√®te

---

## R√©sultat attendu

```
üìä LH_Energie_Bronze/Tables/
‚îú‚îÄ‚îÄ besoins_energetiques (168 lignes - consommation horaire 1 semaine)
‚îú‚îÄ‚îÄ production_solaire (175 lignes - 25 panneaux √ó 7 jours)
‚îî‚îÄ‚îÄ production_eolienne (840 lignes - 5 turbines √ó 168 heures)

üìã Variables pipeline :
‚îú‚îÄ‚îÄ FichiersTraites : ["besoins_energetiques.csv", "production_solaire.csv", "production_eolienne.csv"]
‚îî‚îÄ‚îÄ NombreFichiers : 3
```

---

# Section Analyse : Interpr√©tation des r√©sultats - Atelier 1

## Rappel de la probl√©matique

**Une usine de production traditionnelle migre vers un mod√®le hybride solaire-√©olien. Comment automatiser l'ingestion de donn√©es √©nerg√©tiques h√©t√©rog√®nes pour analyser les besoins actuels et identifier les sources renouvelables disponibles, sans intervention manuelle et avec validation de la compl√©tude ?**

---

## Analyse des r√©sultats obtenus

### R√©sultats techniques

Apr√®s ex√©cution du pipeline `PL_Ingestion_Energie_Bronze`, v√©rifiez dans **LH_Energie_Bronze** ‚Üí **Tables** :

| Table                  | Lignes obtenues | Type de donn√©es                 | P√©riode couverte        |
| ---------------------- | --------------- | ------------------------------- | ----------------------- |
| `besoins_energetiques` | 168             | Consommation horaire de l'usine | 1 semaine (7j √ó 24h)    |
| `production_solaire`   | 175             | Rendement des panneaux par zone | 7 jours √ó 25 panneaux   |
| `production_eolienne`  | 840             | Donn√©es des turbines            | 168 heures √ó 5 turbines |

### Variables de tra√ßabilit√©

```
üìã Variables pipeline :
‚îú‚îÄ‚îÄ FichiersTraites : ["besoins_energetiques.csv", "production_solaire.csv", "production_eolienne.csv"]
‚îú‚îÄ‚îÄ FichierActuel : "production_eolienne.csv" (dernier trait√©)
‚îî‚îÄ‚îÄ NombreFichiers : 3
```

---

## 

## Questions d'analyse guid√©e

### Question 1 : Validation de la compl√©tude des sources

**Observez la variable `FichiersTraites`** :

```json
["besoins_energetiques.csv", "production_solaire.csv", "production_eolienne.csv"]
```

**Calculez le taux de compl√©tude** :

```
Formule : (Fichiers trait√©s / Fichiers attendus) √ó 100
R√©sultat : (3 / 3) √ó 100 = 100%
```

**Interpr√©tation** :

-  Les **3 sources de donn√©es** sont pr√©sentes et ont √©t√© ing√©r√©es
-  Aucune source manquante ‚Üí l'analyse √©nerg√©tique peut √™tre men√©e
-  Le syst√®me d√©tecte automatiquement les fichiers pr√©sents

 **Impact m√©tier** : Si un fichier manque demain (ex: production_solaire.csv), la variable `NombreFichiers` serait = 2 au lieu de 3, ce qui d√©clencherait une alerte.

---

### Question 2 : Granularit√© temporelle des besoins √©nerg√©tiques

**Analysez la table `besoins_energetiques`** :

```sql
SELECT COUNT(*) as NbReleves FROM besoins_energetiques
-- R√©sultat : 168 lignes
```

**Calculez la fr√©quence de mesure** :

```
168 relev√©s sur 7 jours = 168 / 7 = 24 relev√©s/jour
24 relev√©s/jour = 1 relev√©/heure
```

**Interpr√©tation** :

-  **Granularit√© horaire** : La consommation est mesur√©e chaque heure
-  **P√©riode** : 7 jours complets (1 semaine type)
-  **Pr√©cision** : Suffisante pour identifier les pics de consommation

 **Impact m√©tier** : Permet d'analyser les patterns de consommation (jour/nuit, jour de semaine/weekend) et d'ajuster la production en cons√©quence.

**Exemple d'analyse compl√©mentaire** :

```sql
SELECT 
    DATEPART(hour, Horodatage) as Heure,
    AVG(Consommation_kWh) as Conso_Moyenne
FROM besoins_energetiques
GROUP BY DATEPART(hour, Horodatage)
ORDER BY Heure
```

 **Insight attendu** : Identifier les heures de pointe (ex: 8h-18h pour une usine)

---

### Question 3 : Couverture photovolta√Øque

**Analysez la table `production_solaire`** :

```sql
SELECT COUNT(*) as NbReleves FROM production_solaire
-- R√©sultat : 175 lignes
```

**Calculez le nombre de panneaux** :

```
175 relev√©s / 7 jours = 25 panneaux solaires
```

**V√©rifiez la r√©partition g√©ographique** :

```sql
SELECT ZoneInstallation, COUNT(*) as NbPanneaux
FROM production_solaire
GROUP BY ZoneInstallation
ORDER BY NbPanneaux DESC
```

**R√©sultat attendu** :

| Zone       | Nb Panneaux | % du total |
| ---------- | ----------- | ---------- |
| Toit Nord  | 7           | 28%        |
| Toit Sud   | 7           | 28%        |
| Parking    | 6           | 24%        |
| Fa√ßade Est | 5           | 20%        |

**Interpr√©tation** :

-  **25 panneaux** r√©partis sur 4 zones
-  **Couverture √©quilibr√©e** : Toits (56%), Parking (24%), Fa√ßade (20%)
-  **Redondance g√©ographique** : Si une zone est ombrag√©e, les autres compensent

 **Impact m√©tier** : Diversification des emplacements pour maximiser la production sur toute la journ√©e (Est le matin, Sud √† midi, Ouest l'apr√®s-midi).

---

### Question 4 : Capacit√© √©olienne et fr√©quence de mesure

**Analysez la table `production_eolienne`** :

```sql
SELECT COUNT(*) as NbReleves FROM production_eolienne
-- R√©sultat : 840 lignes
```

**Calculez le nombre de turbines et la fr√©quence** :

```
840 relev√©s / 168 heures (7j √ó 24h) = 5 turbines
5 relev√©s par heure = 1 relev√© toutes les 12 minutes par turbine
```

**Interpr√©tation** :

-  **5 turbines √©oliennes** en production
-  **Fr√©quence √©lev√©e** : 1 mesure toutes les 12 minutes
-  **Granularit√© fine** : Permet de d√©tecter les variations rapides de vent

 **Impact m√©tier** : La haute fr√©quence permet d'ajuster la consommation en temps quasi-r√©el selon la production √©olienne (ex: lancer des machines √©nergivores quand le vent souffle fort).

**V√©rifiez la distribution** :

```sql
SELECT TurbineID, COUNT(*) as NbReleves
FROM production_eolienne
GROUP BY TurbineID
ORDER BY TurbineID
```

**R√©sultat attendu** :

| Turbine | Nb Relev√©s | % du total |
| ------- | ---------- | ---------- |
| EOL-01  | 168        | 20%        |
| EOL-02  | 168        | 20%        |
| EOL-03  | 168        | 20%        |
| EOL-04  | 168        | 20%        |
| EOL-05  | 168        | 20%        |

**Interpr√©tation** : Distribution **parfaitement √©quilibr√©e** ‚Üí Toutes les turbines sont op√©rationnelles.

---

### Question 5 : Comparaison des volumes de donn√©es par source

**Synth√®se des volumes** :

| Source  | Lignes | √âquipements | Fr√©quence | Volume relatif |
| ------- | ------ | ----------- | --------- | -------------- |
| Besoins | 168    | 1 usine     | 1/heure   | 16%            |
| Solaire | 175    | 25 panneaux | 1/jour    | 17%            |
| √âolien  | 840    | 5 turbines  | 5/heure   | 67%            |

**Interpr√©tation** :

-  **L'√©olien repr√©sente 67%** des donn√©es ing√©r√©es
-  Raison : Fr√©quence √©lev√©e (5 relev√©s/h) + 5 √©quipements
-  **Volumes d√©s√©quilibr√©s** mais normaux (capteurs diff√©rents)

 **Impact m√©tier** :

- Les co√ªts de stockage seront principalement li√©s aux donn√©es √©oliennes
- Les traitements en temps r√©el devront prioriser les flux √©oliens
- Le solaire peut √™tre agr√©g√© quotidiennement sans perte d'information

---

## Synth√®se : R√©ponse √† la probl√©matique

### Probl√©matique rappel√©e

> Comment automatiser l'ingestion de donn√©es √©nerg√©tiques h√©t√©rog√®nes pour analyser les besoins actuels et identifier les sources renouvelables disponibles, sans intervention manuelle et avec validation de la compl√©tude ?

### Tableau de satisfaction des objectifs

| Objectif                      | M√©thode                              | R√©sultat                                | Impact m√©tier                             |
| ----------------------------- | ------------------------------------ | --------------------------------------- | ----------------------------------------- |
| **1. Automatisation**         | Pipeline dynamique avec Get Metadata | ‚úÖ 0 intervention manuelle               | √âconomie de 2h/jour de travail technicien |
| **2. D√©tection dynamique**    | Child items sur dossier landing      | ‚úÖ 3 fichiers d√©tect√©s automatiquement   | Fonctionne pour 3, 10 ou 100 fichiers     |
| **3. Filtrage intelligent**   | If Condition sur `.csv`              | ‚úÖ Seuls les CSV trait√©s                 | Ignore logs, images, fichiers temporaires |
| **4. Cr√©ation tables Bronze** | Copy Data avec nom dynamique         | ‚úÖ 3 tables cr√©√©es (1183 lignes totales) | Donn√©es structur√©es et requ√™tables        |
| **5. Validation compl√©tude**  | Variable `FichiersTraites`           | ‚úÖ 100% de compl√©tude (3/3)              | Alerte automatique si source manquante    |
| **6. Tra√ßabilit√©**            | Append Variable                      | ‚úÖ Historique des fichiers ing√©r√©s       | Audit et conformit√© RGPD                  |

---

## Indicateurs cl√©s de performance (KPI)

### KPI 1 : Taux d'automatisation

```
Formule : (Fichiers trait√©s automatiquement / Total fichiers) √ó 100
R√©sultat : (3 / 3) √ó 100 = 100%
Cible : > 95%
Statut : ‚úÖ Objectif d√©pass√©
```

### KPI 2 : Temps d'ingestion

```
Mesure : Temps d'ex√©cution du pipeline
R√©sultat : 15-45 secondes pour 3 fichiers (1183 lignes)
Benchmark : ~15 sec/fichier en moyenne
Statut : ‚úÖ Performance acceptable
```

### KPI 3 : Taux de compl√©tude des sources

```
Formule : (Sources ing√©r√©es / Sources attendues) √ó 100
R√©sultat : (3 / 3) √ó 100 = 100%
Cible : 100%
Statut : ‚úÖ Toutes les sources pr√©sentes
```

### KPI 4 : Qualit√© des donn√©es (int√©grit√©)

```
V√©rification : Nombre de lignes par table
R√©sultat : 
  - besoins_energetiques : 168 lignes (7j √ó 24h) ‚úÖ
  - production_solaire : 175 lignes (25 panneaux √ó 7j) ‚úÖ
  - production_eolienne : 840 lignes (5 turbines √ó 168h) ‚úÖ
Statut : ‚úÖ Aucune perte de donn√©es
```

---

## Insights m√©tier

### Insight 1 : √âquilibre √©nerg√©tique pr√©liminaire

**Calculez la capacit√© renouvelable th√©orique** :

```sql
-- Production solaire moyenne
SELECT AVG(Production_kWh) as Prod_Solaire_Moyenne
FROM production_solaire
-- R√©sultat attendu : ~350 kWh/jour (25 panneaux √ó 14 kWh)

-- Production √©olienne moyenne
SELECT AVG(Production_kWh) as Prod_Eolienne_Moyenne
FROM production_eolienne
-- R√©sultat attendu : ~1200 kWh/jour (5 turbines √ó 240 kWh)

-- Besoin √©nerg√©tique quotidien
SELECT SUM(Consommation_kWh) / 7 as Conso_Quotidienne
FROM besoins_energetiques
-- R√©sultat attendu : ~1800 kWh/jour
```

**Analyse de couverture** :

```
Production renouvelable : 350 (solaire) + 1200 (√©olien) = 1550 kWh/jour
Besoin √©nerg√©tique : 1800 kWh/jour
Taux de couverture : (1550 / 1800) √ó 100 = 86%
D√©ficit : 1800 - 1550 = 250 kWh/jour (14%)
```

**Interpr√©tation** :

-  **86% d'autonomie √©nerg√©tique** avec les sources renouvelables
-  **14% de d√©ficit** √† combler (r√©seau traditionnel ou batteries)
-  **Objectif atteint** : R√©duction significative de la d√©pendance au r√©seau

üí° **Recommandations m√©tier** :

1. Ajouter **5 panneaux solaires** suppl√©mentaires (+70 kWh/j) pour atteindre 90% d'autonomie
2. Installer un **syst√®me de batteries** de 250 kWh pour stocker les surplus et couvrir les pics
3. Impl√©menter un **syst√®me de d√©lestage intelligent** pour reporter certaines charges non prioritaires

---

### Insight 2 : Patterns temporels de consommation

**Identifiez les heures de pointe** :

```sql
SELECT 
    DATEPART(hour, Horodatage) as Heure,
    AVG(Consommation_kWh) as Conso_Moyenne,
    MAX(Consommation_kWh) as Conso_Max
FROM besoins_energetiques
GROUP BY DATEPART(hour, Horodatage)
ORDER BY Conso_Moyenne DESC
```

**R√©sultat attendu (heures de pointe)** :

| Heure | Conso Moyenne | Conso Max |
| ----- | ------------- | --------- |
| 14h   | 95 kWh        | 110 kWh   |
| 15h   | 92 kWh        | 105 kWh   |
| 10h   | 88 kWh        | 100 kWh   |

**Interpr√©tation** :

-  **Pic de consommation** : 14h-15h (heures de production maximale de l'usine)
-  **Co√Øncidence** : Production solaire maximale √©galement √† cette p√©riode
-  **Opportunit√©** : Synchronisation naturelle production solaire / consommation

 **Recommandations m√©tier** :

- **Optimiser** : Lancer les processus √©nergivores entre 12h-16h (solaire au max)
- **Diff√©rer** : Recharger les batteries et pr√©chauffer les √©quipements t√¥t le matin (√©olien nocturne)
- **√âviter** : Ne pas lancer de gros consommateurs entre 18h-22h (creux de production)

---

### Insight 3 : Variabilit√© de la production √©olienne

**Analysez la stabilit√©** :

```sql
SELECT 
    TurbineID,
    AVG(Production_kWh) as Prod_Moyenne,
    STDEV(Production_kWh) as Ecart_Type,
    MIN(Production_kWh) as Prod_Min,
    MAX(Production_kWh) as Prod_Max
FROM production_eolienne
GROUP BY TurbineID
```

**R√©sultat attendu** :

| Turbine | Moyenne | √âcart-type | Min | Max | Coefficient variation |
| ------- | ------- | ---------- | --- | --- | --------------------- |
| EOL-01  | 10 kWh  | 4.2 kWh    | 0   | 18  | 42%                   |
| EOL-02  | 10 kWh  | 4.5 kWh    | 0   | 19  | 45%                   |
| ...     | ...     | ...        | ... | ... | ...                   |

**Interpr√©tation** :

-  **Variabilit√© √©lev√©e** : Coefficient de variation ~40-45%
-  **Impr√©visibilit√©** : Production fluctue de 0 √† 18-19 kWh
-  **Besoin de stockage** : Les batteries sont essentielles pour lisser la production

 **Recommandations m√©tier** :

- **Court terme** : Syst√®me de batteries de 500 kWh (couvre 6h de d√©ficit)
- **Moyen terme** : Contrat de backup avec le r√©seau traditionnel
- **Long terme** : Diversifier avec une 2√®me source pr√©visible (hydro√©lectrique si possible)

---

## üéì Questions d'√©valuation pour l'apprenant

### Niveau 1 : Compr√©hension technique

**Q1** : Combien de fichiers ont √©t√© ing√©r√©s automatiquement ?

<details>
<summary>R√©ponse</summary>
3 fichiers CSV : besoins_energetiques.csv, production_solaire.csv, production_eolienne.csv
</details>

**Q2** : Quelle activit√© permet de d√©tecter dynamiquement les fichiers pr√©sents ?

<details>
<summary>R√©ponse</summary>
Get Metadata avec l'option "Child items" qui retourne la liste de tous les fichiers du dossier landing
</details>

**Q3** : Pourquoi utilise-t-on une If Condition dans la boucle ForEach ?

<details>
<summary>R√©ponse</summary>
Pour filtrer uniquement les fichiers CSV et ignorer les autres types de fichiers (logs, images, fichiers temporaires)
</details>

---

### Niveau 2 : Analyse m√©tier

**Q4** : Calculez le taux d'autonomie √©nerg√©tique de l'usine avec les sources renouvelables.

<details>
<summary>R√©ponse</summary>
Production renouvelable totale : ~1550 kWh/jour (350 solaire + 1200 √©olien)
Consommation : ~1800 kWh/jour
Taux d'autonomie : (1550 / 1800) √ó 100 = 86%
Conclusion : L'usine couvre 86% de ses besoins avec le renouvelable, il reste 14% √† combler
</details>

**Q5** : Pourquoi la production √©olienne repr√©sente-t-elle 67% du volume de donn√©es ing√©r√©es ?

<details>
<summary>R√©ponse</summary>
Trois raisons :
1. Fr√©quence de mesure √©lev√©e : 5 relev√©s/heure (vs 1/heure pour besoins, 1/jour pour solaire)
2. Nombre d'√©quipements : 5 turbines (vs 1 usine, 25 panneaux)
3. Granularit√© n√©cessaire : Le vent varie rapidement, n√©cessite un monitoring fin
Calcul : 5 turbines √ó 168 heures √ó 1 relev√© = 840 lignes (67% de 1183 lignes totales)
</details>

**Q6** : √Ä quelle heure l'usine devrait-elle planifier ses processus les plus √©nergivores ?

<details>
<summary>R√©ponse</summary>
Entre 12h et 16h, car :
- Production solaire maximale pendant cette p√©riode
- Co√Øncidence avec les heures de production habituelles de l'usine
- Permet de maximiser l'autoconsommation et r√©duire la d√©pendance au r√©seau
√Ä √©viter : 18h-22h (creux de production, besoin de batteries ou r√©seau traditionnel)
</details>

---

### Niveau 3 : Optimisation et d√©cision strat√©gique

**Q7** : Si demain un 4√®me fichier `stockage_batteries.csv` appara√Æt dans le dossier, que se passera-t-il ?

<details>
<summary>R√©ponse</summary>
Le pipeline est **totalement dynamique** :
1. Get Metadata d√©tectera 4 fichiers au lieu de 3
2. ForEach bouclera 4 fois au lieu de 3
3. If Condition v√©rifiera `.csv` (valid√© ‚úÖ)
4. Copy Data cr√©era automatiquement la table `stockage_batteries`
5. Variable `FichiersTraites` contiendra 4 √©l√©ments
6. Variable `NombreFichiers` = 4

Aucune modification du code n√©cessaire ! C'est la force du pipeline dynamique.

</details>

**Q8** : L'usine veut passer de 5 √† 50 turbines √©oliennes. Quels ajustements feriez-vous au pipeline ?

<details>
<summary>R√©ponse</summary>
**Pipeline actuel** : Aucun changement n√©cessaire ! Le pipeline est d√©j√† pr√©vu pour scaler.

**Optimisations recommand√©es** :

1. **Partitionnement** : Cr√©er des sous-dossiers par zone g√©ographique
   - `landing/zone-nord/production_eolienne.csv`
   - `landing/zone-sud/production_eolienne.csv`
2. **Parall√©lisation** : Modifier ForEach avec `Sequential = false` pour traiter les fichiers en parall√®le
3. **Filtrage temporel** : Ajouter une activit√© pour ne traiter que les fichiers de moins de 24h (√©viter les re-traitements)
4. **Archivage** : Ajouter une activit√© Copy pour d√©placer les fichiers trait√©s vers un dossier `archive/`
5. **Monitoring** : Ajouter des alertes si `NombreFichiers` ‚â† valeur attendue

**Infrastructure** :

- Augmenter la capacit√© de stockage Lakehouse
- Passer √† un tier de performance sup√©rieur si latence > 60 sec

</details>

**Q9** : Comment utiliseriez-vous la variable `FichiersTraites` pour impl√©menter un syst√®me d'alerte ?

<details>
<summary>R√©ponse</summary>
**M√©thode 1 : Email d'alerte si fichier manquant**
Ajouter apr√®s ForEach :
```
If Condition : @equals(length(variables('FichiersTraites')), 3)
 False branch ‚Üí Send Email :
 - Subject : "‚ö†Ô∏è Alerte : Fichier manquant"
 - Body : "Fichiers attendus : 3. Fichiers trait√©s : @{length(variables('FichiersTraites'))}"
```

**M√©thode 2 : Log dans une table d'audit** Ajouter apr√®s ForEach :

```
Copy Data ‚Üí Table `audit_ingestion`
  - Pipeline : PL_Ingestion_Energie_Bronze
  - Date : @utcNow()
  - Fichiers trait√©s : @{variables('FichiersTraites')}
  - Nombre : @{length(variables('FichiersTraites'))}
  - Statut : @{if(equals(length(variables('FichiersTraites')), 3), 'OK', 'INCOMPLET')}
```

**M√©thode 3 : Dashboard Power BI**

- Cr√©er une mesure DAX qui compare fichiers attendus vs fichiers trait√©s
- Alerte visuelle (rouge) si < 100% de compl√©tude

</details>

---

## Checklist de validation finale

Avant de consid√©rer l'atelier termin√©, v√©rifiez que l'apprenant peut :

### Comp√©tences techniques

- [ ] Expliquer le r√¥le de Get Metadata et Child items
- [ ] Justifier l'utilisation de ForEach vs autres boucles
- [ ] Interpr√©ter l'expression `@item().name` dans le contexte de ForEach
- [ ] Expliquer la diff√©rence entre Append Variable et Set Variable

### Comp√©tences m√©tier

- [ ] Calculer le taux d'autonomie √©nerg√©tique
- [ ] Identifier les heures de pointe de consommation
- [ ] √âvaluer la variabilit√© de la production √©olienne
- [ ] Proposer des optimisations de planning de production

### Comp√©tences transversales

- [ ] Pr√©senter les KPI de mani√®re structur√©e
- [ ] Relier les volumes de donn√©es aux d√©cisions m√©tier
- [ ] Anticiper les besoins de scaling (50 turbines)
- [ ] Proposer un syst√®me d'alerte automatique

---

## Conclusion : Valeur ajout√©e du pipeline

### Situation AVANT (processus manuel)

| Crit√®re                   | √âtat          | Impact                                    |
| ------------------------- | ------------- | ----------------------------------------- |
| **Temps d'ingestion**     | 2h/jour       | Co√ªt : 400‚Ç¨/mois (salaire technicien)     |
| **Erreurs humaines**      | 1-2/semaine   | Analyses fauss√©es, d√©cisions erron√©es     |
| **Validation compl√©tude** | Manuelle      | Risque de fichier oubli√© : 10%            |
| **Tra√ßabilit√©**           | Fichier Excel | Pas d'audit fiable                        |
| **R√©activit√©**            | J+1           | D√©cisions prises sur donn√©es de la veille |

### Situation APR√àS (pipeline automatis√©)

| Crit√®re                   | √âtat           | Impact                                 |
| ------------------------- | -------------- | -------------------------------------- |
| **Temps d'ingestion**     | 15-45 sec      | Co√ªt : 0‚Ç¨/mois (automatis√©)            |
| **Erreurs humaines**      | 0              | Donn√©es fiables √† 100%                 |
| **Validation compl√©tude** | Automatique    | Alerte imm√©diate si fichier manquant   |
| **Tra√ßabilit√©**           | Variable Array | Audit complet et historis√©             |
| **R√©activit√©**            | Temps r√©el     | D√©cisions prises sur donn√©es actuelles |

### Gains quantifi√©s

| Indicateur           | Avant   | Apr√®s        | Gain       |
| -------------------- | ------- | ------------ | ---------- |
| **Temps traitement** | 2h/jour | 45 sec/jour  | **99.6%**  |
| **Co√ªt mensuel**     | 400‚Ç¨    | 5‚Ç¨ (compute) | **98.75%** |
| **Taux d'erreur**    | 10%     | 0%           | **100%**   |
| **D√©lai d√©cision**   | 24h     | 1h           | **95.8%**  |

### ROI (Return on Investment)

**Investissement initial** :

- D√©veloppement pipeline : 4h √ó 80‚Ç¨/h = 320‚Ç¨
- Formation : 2h √ó 80‚Ç¨/h = 160‚Ç¨
- **Total** : 480‚Ç¨

**√âconomies mensuelles** :

- Temps technicien : 400‚Ç¨/mois
- R√©duction erreurs : ~50‚Ç¨/mois (co√ªt moyen d'une erreur)
- **Total** : 450‚Ç¨/mois

**Retour sur investissement** :

```
ROI = (480‚Ç¨) / (450‚Ç¨/mois) = 1.07 mois
```

üí° **Conclusion** : Le pipeline est rentabilis√© en **5 semaines** !

---

## üöÄ Pour aller plus loin

### 1. **Ajouter une d√©tection d'anomalies**

```sql
-- D√©tecter les valeurs aberrantes
SELECT *
FROM production_eolienne
WHERE Production_kWh > (SELECT AVG(Production_kWh) + 3 * STDEV(Production_kWh) FROM production_eolienne)
   OR Production_kWh < 0
```

### 2. **Cr√©er un dashboard temps r√©el Power BI**

- KPI 1 : Taux d'autonomie √©nerg√©tique (jauge)
- KPI 2 : Production vs Consommation (graphique ligne)
- KPI 3 : √âtat des sources (indicateurs color√©s)
- KPI 4 : Pr√©vision de couverture J+1 (ML)

### 3. **Impl√©menter un syst√®me de pr√©vision**

- Machine Learning pour pr√©dire la production √©olienne (bas√© sur m√©t√©o)
- Optimisation du planning de production en cons√©quence
- Achat d'√©nergie r√©seau uniquement si production pr√©visionnelle < besoins

### 4. **Ajouter une orchestration multi-pipelines**

```
Pipeline 1 : Ingestion (actuel)
    ‚Üì
Pipeline 2 : Nettoyage et validation
    ‚Üì
Pipeline 3 : Calcul des KPI et agr√©gations
    ‚Üì
Pipeline 4 : Alimentation Power BI
```

---

**Cette section d'analyse transforme un exercice technique en une v√©ritable √©tude de cas ROI-driven, exploitable en entreprise !**





---

**Prochaine √©tape** : Atelier 2 - Transformation Bronze ‚Üí Silver avec nettoyage conditionnel, lookup de r√©f√©rence et Until loop
